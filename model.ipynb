{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import kagglehub\n",
    "stop_words = stopwords.words('english')\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.9), please consider upgrading to the latest version (0.3.10).\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download('abhi8923shriv/sentiment-analysis-dataset')\n",
    "train_dataset = path+'/train.csv'\n",
    "test_dataset = path+'/test.csv'\n",
    "train_df = pd.read_csv(train_dataset, encoding='ISO-8859-1')\n",
    "test_df = pd.read_csv(test_dataset, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.dropna(subset = \"text\")[[\"text\", \"sentiment\"]]\n",
    "test = test_df.dropna()[[\"text\", \"sentiment\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# without preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train[\"text\"].values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(train[\"sentiment\"].values)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, stratify=y, random_state=42, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x_train_transformed = vectorizer.fit_transform(x_train)\n",
    "x_valid_transformed = vectorizer.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7084    0.6088    0.6548      2334\n",
      "           1     0.6189    0.7406    0.6743      3335\n",
      "           2     0.7819    0.6823    0.7287      2575\n",
      "\n",
      "    accuracy                         0.6851      8244\n",
      "   macro avg     0.7031    0.6773    0.6860      8244\n",
      "weighted avg     0.6952    0.6851    0.6858      8244\n",
      "\n",
      "-----------------------------------\n",
      "Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7881    0.3475    0.4823      2334\n",
      "           1     0.5163    0.8642    0.6464      3335\n",
      "           2     0.7844    0.4975    0.6088      2575\n",
      "\n",
      "    accuracy                         0.6033      8244\n",
      "   macro avg     0.6963    0.5697    0.5792      8244\n",
      "weighted avg     0.6770    0.6033    0.5882      8244\n",
      "\n",
      "-----------------------------------\n",
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7552    0.5617    0.6442      2334\n",
      "           1     0.6031    0.8060    0.6899      3335\n",
      "           2     0.8172    0.6509    0.7246      2575\n",
      "\n",
      "    accuracy                         0.6884      8244\n",
      "   macro avg     0.7251    0.6729    0.6863      8244\n",
      "weighted avg     0.7130    0.6884    0.6878      8244\n",
      "\n",
      "-----------------------------------\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7230    0.5313    0.6125      2334\n",
      "           1     0.5986    0.7703    0.6737      3335\n",
      "           2     0.7774    0.6753    0.7228      2575\n",
      "\n",
      "    accuracy                         0.6730      8244\n",
      "   macro avg     0.6997    0.6590    0.6696      8244\n",
      "weighted avg     0.6897    0.6730    0.6717      8244\n",
      "\n",
      "-----------------------------------\n",
      "XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7476    0.5407    0.6275      2334\n",
      "           1     0.6062    0.7874    0.6850      3335\n",
      "           2     0.7905    0.6827    0.7327      2575\n",
      "\n",
      "    accuracy                         0.6849      8244\n",
      "   macro avg     0.7148    0.6703    0.6817      8244\n",
      "weighted avg     0.7038    0.6849    0.6836      8244\n",
      "\n",
      "-----------------------------------\n",
      "LightGBM\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46208\n",
      "[LightGBM] [Info] Number of data points in the train set: 19236, number of used features: 1106\n",
      "[LightGBM] [Info] Start training from score -1.261719\n",
      "[LightGBM] [Info] Start training from score -0.904970\n",
      "[LightGBM] [Info] Start training from score -1.163858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Egen\\Kuliah\\Discover NUS\\Natural Language Processing\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7184    0.5716    0.6366      2334\n",
      "           1     0.6274    0.7559    0.6857      3335\n",
      "           2     0.7835    0.7208    0.7508      2575\n",
      "\n",
      "    accuracy                         0.6927      8244\n",
      "   macro avg     0.7097    0.6827    0.6910      8244\n",
      "weighted avg     0.7019    0.6927    0.6921      8244\n",
      "\n",
      "-----------------------------------\n",
      "CatBoost\n",
      "Learning rate set to 0.092005\n",
      "0:\tlearn: 1.0803317\ttotal: 350ms\tremaining: 5m 49s\n",
      "1:\tlearn: 1.0663912\ttotal: 531ms\tremaining: 4m 25s\n",
      "2:\tlearn: 1.0545365\ttotal: 717ms\tremaining: 3m 58s\n",
      "3:\tlearn: 1.0440508\ttotal: 899ms\tremaining: 3m 43s\n",
      "4:\tlearn: 1.0344776\ttotal: 1.09s\tremaining: 3m 37s\n",
      "5:\tlearn: 1.0258789\ttotal: 1.28s\tremaining: 3m 31s\n",
      "6:\tlearn: 1.0188947\ttotal: 1.45s\tremaining: 3m 26s\n",
      "7:\tlearn: 1.0125502\ttotal: 1.63s\tremaining: 3m 22s\n",
      "8:\tlearn: 1.0066023\ttotal: 1.81s\tremaining: 3m 19s\n",
      "9:\tlearn: 1.0009262\ttotal: 2s\tremaining: 3m 17s\n",
      "10:\tlearn: 0.9955352\ttotal: 2.18s\tremaining: 3m 16s\n",
      "11:\tlearn: 0.9914821\ttotal: 2.36s\tremaining: 3m 14s\n",
      "12:\tlearn: 0.9879205\ttotal: 2.54s\tremaining: 3m 12s\n",
      "13:\tlearn: 0.9838803\ttotal: 2.72s\tremaining: 3m 11s\n",
      "14:\tlearn: 0.9797788\ttotal: 2.9s\tremaining: 3m 10s\n",
      "15:\tlearn: 0.9758895\ttotal: 3.08s\tremaining: 3m 9s\n",
      "16:\tlearn: 0.9723310\ttotal: 3.25s\tremaining: 3m 8s\n",
      "17:\tlearn: 0.9688684\ttotal: 3.44s\tremaining: 3m 7s\n",
      "18:\tlearn: 0.9658460\ttotal: 3.63s\tremaining: 3m 7s\n",
      "19:\tlearn: 0.9629833\ttotal: 3.81s\tremaining: 3m 6s\n",
      "20:\tlearn: 0.9598675\ttotal: 4s\tremaining: 3m 6s\n",
      "21:\tlearn: 0.9573641\ttotal: 4.17s\tremaining: 3m 5s\n",
      "22:\tlearn: 0.9547447\ttotal: 4.35s\tremaining: 3m 4s\n",
      "23:\tlearn: 0.9515633\ttotal: 4.54s\tremaining: 3m 4s\n",
      "24:\tlearn: 0.9493257\ttotal: 4.72s\tremaining: 3m 3s\n",
      "25:\tlearn: 0.9468704\ttotal: 4.9s\tremaining: 3m 3s\n",
      "26:\tlearn: 0.9441216\ttotal: 5.08s\tremaining: 3m 2s\n",
      "27:\tlearn: 0.9419175\ttotal: 5.25s\tremaining: 3m 2s\n",
      "28:\tlearn: 0.9395576\ttotal: 5.43s\tremaining: 3m 1s\n",
      "29:\tlearn: 0.9372800\ttotal: 5.61s\tremaining: 3m 1s\n",
      "30:\tlearn: 0.9351440\ttotal: 5.79s\tremaining: 3m\n",
      "31:\tlearn: 0.9326912\ttotal: 5.98s\tremaining: 3m\n",
      "32:\tlearn: 0.9309549\ttotal: 6.16s\tremaining: 3m\n",
      "33:\tlearn: 0.9290238\ttotal: 6.34s\tremaining: 3m\n",
      "34:\tlearn: 0.9271804\ttotal: 6.52s\tremaining: 2m 59s\n",
      "35:\tlearn: 0.9252870\ttotal: 6.71s\tremaining: 2m 59s\n",
      "36:\tlearn: 0.9236906\ttotal: 6.88s\tremaining: 2m 59s\n",
      "37:\tlearn: 0.9218448\ttotal: 7.07s\tremaining: 2m 58s\n",
      "38:\tlearn: 0.9196145\ttotal: 7.25s\tremaining: 2m 58s\n",
      "39:\tlearn: 0.9178843\ttotal: 7.43s\tremaining: 2m 58s\n",
      "40:\tlearn: 0.9163113\ttotal: 7.62s\tremaining: 2m 58s\n",
      "41:\tlearn: 0.9144933\ttotal: 7.81s\tremaining: 2m 58s\n",
      "42:\tlearn: 0.9127215\ttotal: 8s\tremaining: 2m 57s\n",
      "43:\tlearn: 0.9109911\ttotal: 8.18s\tremaining: 2m 57s\n",
      "44:\tlearn: 0.9094298\ttotal: 8.35s\tremaining: 2m 57s\n",
      "45:\tlearn: 0.9079303\ttotal: 8.53s\tremaining: 2m 57s\n",
      "46:\tlearn: 0.9068518\ttotal: 8.72s\tremaining: 2m 56s\n",
      "47:\tlearn: 0.9054169\ttotal: 8.93s\tremaining: 2m 57s\n",
      "48:\tlearn: 0.9037123\ttotal: 9.12s\tremaining: 2m 56s\n",
      "49:\tlearn: 0.9025259\ttotal: 9.31s\tremaining: 2m 56s\n",
      "50:\tlearn: 0.9008217\ttotal: 9.49s\tremaining: 2m 56s\n",
      "51:\tlearn: 0.8995443\ttotal: 9.67s\tremaining: 2m 56s\n",
      "52:\tlearn: 0.8983669\ttotal: 9.85s\tremaining: 2m 56s\n",
      "53:\tlearn: 0.8965801\ttotal: 10s\tremaining: 2m 55s\n",
      "54:\tlearn: 0.8953992\ttotal: 10.2s\tremaining: 2m 55s\n",
      "55:\tlearn: 0.8940306\ttotal: 10.4s\tremaining: 2m 55s\n",
      "56:\tlearn: 0.8927583\ttotal: 10.6s\tremaining: 2m 54s\n",
      "57:\tlearn: 0.8913484\ttotal: 10.8s\tremaining: 2m 54s\n",
      "58:\tlearn: 0.8905270\ttotal: 10.9s\tremaining: 2m 54s\n",
      "59:\tlearn: 0.8890604\ttotal: 11.1s\tremaining: 2m 54s\n",
      "60:\tlearn: 0.8879810\ttotal: 11.3s\tremaining: 2m 54s\n",
      "61:\tlearn: 0.8870249\ttotal: 11.5s\tremaining: 2m 53s\n",
      "62:\tlearn: 0.8861812\ttotal: 11.7s\tremaining: 2m 53s\n",
      "63:\tlearn: 0.8852019\ttotal: 11.8s\tremaining: 2m 53s\n",
      "64:\tlearn: 0.8843137\ttotal: 12s\tremaining: 2m 53s\n",
      "65:\tlearn: 0.8832619\ttotal: 12.2s\tremaining: 2m 52s\n",
      "66:\tlearn: 0.8822465\ttotal: 12.4s\tremaining: 2m 52s\n",
      "67:\tlearn: 0.8812184\ttotal: 12.6s\tremaining: 2m 52s\n",
      "68:\tlearn: 0.8803559\ttotal: 12.8s\tremaining: 2m 52s\n",
      "69:\tlearn: 0.8793064\ttotal: 12.9s\tremaining: 2m 52s\n",
      "70:\tlearn: 0.8783780\ttotal: 13.1s\tremaining: 2m 51s\n",
      "71:\tlearn: 0.8773943\ttotal: 13.3s\tremaining: 2m 51s\n",
      "72:\tlearn: 0.8763003\ttotal: 13.5s\tremaining: 2m 51s\n",
      "73:\tlearn: 0.8754304\ttotal: 13.7s\tremaining: 2m 51s\n",
      "74:\tlearn: 0.8744845\ttotal: 13.9s\tremaining: 2m 50s\n",
      "75:\tlearn: 0.8734944\ttotal: 14s\tremaining: 2m 50s\n",
      "76:\tlearn: 0.8724319\ttotal: 14.2s\tremaining: 2m 50s\n",
      "77:\tlearn: 0.8717244\ttotal: 14.4s\tremaining: 2m 50s\n",
      "78:\tlearn: 0.8709731\ttotal: 14.6s\tremaining: 2m 50s\n",
      "79:\tlearn: 0.8702946\ttotal: 14.8s\tremaining: 2m 49s\n",
      "80:\tlearn: 0.8697637\ttotal: 15s\tremaining: 2m 49s\n",
      "81:\tlearn: 0.8687507\ttotal: 15.1s\tremaining: 2m 49s\n",
      "82:\tlearn: 0.8679148\ttotal: 15.3s\tremaining: 2m 49s\n",
      "83:\tlearn: 0.8669911\ttotal: 15.5s\tremaining: 2m 49s\n",
      "84:\tlearn: 0.8662959\ttotal: 15.7s\tremaining: 2m 48s\n",
      "85:\tlearn: 0.8653351\ttotal: 15.9s\tremaining: 2m 48s\n",
      "86:\tlearn: 0.8643116\ttotal: 16s\tremaining: 2m 48s\n",
      "87:\tlearn: 0.8635245\ttotal: 16.2s\tremaining: 2m 47s\n",
      "88:\tlearn: 0.8628878\ttotal: 16.4s\tremaining: 2m 47s\n",
      "89:\tlearn: 0.8620588\ttotal: 16.5s\tremaining: 2m 47s\n",
      "90:\tlearn: 0.8612266\ttotal: 16.7s\tremaining: 2m 47s\n",
      "91:\tlearn: 0.8603186\ttotal: 16.9s\tremaining: 2m 46s\n",
      "92:\tlearn: 0.8594767\ttotal: 17.1s\tremaining: 2m 46s\n",
      "93:\tlearn: 0.8588685\ttotal: 17.2s\tremaining: 2m 46s\n",
      "94:\tlearn: 0.8580431\ttotal: 17.4s\tremaining: 2m 45s\n",
      "95:\tlearn: 0.8572522\ttotal: 17.6s\tremaining: 2m 45s\n",
      "96:\tlearn: 0.8564569\ttotal: 17.8s\tremaining: 2m 45s\n",
      "97:\tlearn: 0.8557327\ttotal: 18s\tremaining: 2m 45s\n",
      "98:\tlearn: 0.8549541\ttotal: 18.1s\tremaining: 2m 45s\n",
      "99:\tlearn: 0.8543070\ttotal: 18.3s\tremaining: 2m 44s\n",
      "100:\tlearn: 0.8535666\ttotal: 18.5s\tremaining: 2m 44s\n",
      "101:\tlearn: 0.8529605\ttotal: 18.6s\tremaining: 2m 44s\n",
      "102:\tlearn: 0.8522707\ttotal: 18.8s\tremaining: 2m 43s\n",
      "103:\tlearn: 0.8515340\ttotal: 19s\tremaining: 2m 43s\n",
      "104:\tlearn: 0.8508279\ttotal: 19.2s\tremaining: 2m 43s\n",
      "105:\tlearn: 0.8500206\ttotal: 19.3s\tremaining: 2m 43s\n",
      "106:\tlearn: 0.8492549\ttotal: 19.5s\tremaining: 2m 43s\n",
      "107:\tlearn: 0.8483971\ttotal: 19.7s\tremaining: 2m 42s\n",
      "108:\tlearn: 0.8477491\ttotal: 19.9s\tremaining: 2m 42s\n",
      "109:\tlearn: 0.8470086\ttotal: 20s\tremaining: 2m 42s\n",
      "110:\tlearn: 0.8463359\ttotal: 20.2s\tremaining: 2m 41s\n",
      "111:\tlearn: 0.8453049\ttotal: 20.4s\tremaining: 2m 41s\n",
      "112:\tlearn: 0.8446607\ttotal: 20.6s\tremaining: 2m 41s\n",
      "113:\tlearn: 0.8438837\ttotal: 20.7s\tremaining: 2m 41s\n",
      "114:\tlearn: 0.8430910\ttotal: 20.9s\tremaining: 2m 40s\n",
      "115:\tlearn: 0.8423199\ttotal: 21.1s\tremaining: 2m 40s\n",
      "116:\tlearn: 0.8415335\ttotal: 21.3s\tremaining: 2m 40s\n",
      "117:\tlearn: 0.8406880\ttotal: 21.4s\tremaining: 2m 40s\n",
      "118:\tlearn: 0.8399100\ttotal: 21.6s\tremaining: 2m 40s\n",
      "119:\tlearn: 0.8390795\ttotal: 21.8s\tremaining: 2m 39s\n",
      "120:\tlearn: 0.8383555\ttotal: 22s\tremaining: 2m 39s\n",
      "121:\tlearn: 0.8376374\ttotal: 22.1s\tremaining: 2m 39s\n",
      "122:\tlearn: 0.8370516\ttotal: 22.3s\tremaining: 2m 38s\n",
      "123:\tlearn: 0.8361522\ttotal: 22.5s\tremaining: 2m 38s\n",
      "124:\tlearn: 0.8355903\ttotal: 22.6s\tremaining: 2m 38s\n",
      "125:\tlearn: 0.8348211\ttotal: 22.8s\tremaining: 2m 38s\n",
      "126:\tlearn: 0.8337783\ttotal: 23s\tremaining: 2m 38s\n",
      "127:\tlearn: 0.8329063\ttotal: 23.2s\tremaining: 2m 37s\n",
      "128:\tlearn: 0.8321711\ttotal: 23.3s\tremaining: 2m 37s\n",
      "129:\tlearn: 0.8315926\ttotal: 23.5s\tremaining: 2m 37s\n",
      "130:\tlearn: 0.8309313\ttotal: 23.7s\tremaining: 2m 37s\n",
      "131:\tlearn: 0.8302624\ttotal: 23.8s\tremaining: 2m 36s\n",
      "132:\tlearn: 0.8296671\ttotal: 24s\tremaining: 2m 36s\n",
      "133:\tlearn: 0.8289505\ttotal: 24.2s\tremaining: 2m 36s\n",
      "134:\tlearn: 0.8283919\ttotal: 24.4s\tremaining: 2m 36s\n",
      "135:\tlearn: 0.8277387\ttotal: 24.6s\tremaining: 2m 36s\n",
      "136:\tlearn: 0.8271315\ttotal: 24.7s\tremaining: 2m 35s\n",
      "137:\tlearn: 0.8265384\ttotal: 24.9s\tremaining: 2m 35s\n",
      "138:\tlearn: 0.8257424\ttotal: 25.1s\tremaining: 2m 35s\n",
      "139:\tlearn: 0.8249382\ttotal: 25.3s\tremaining: 2m 35s\n",
      "140:\tlearn: 0.8242926\ttotal: 25.4s\tremaining: 2m 34s\n",
      "141:\tlearn: 0.8237262\ttotal: 25.6s\tremaining: 2m 34s\n",
      "142:\tlearn: 0.8231421\ttotal: 25.8s\tremaining: 2m 34s\n",
      "143:\tlearn: 0.8225011\ttotal: 25.9s\tremaining: 2m 34s\n",
      "144:\tlearn: 0.8215752\ttotal: 26.1s\tremaining: 2m 34s\n",
      "145:\tlearn: 0.8210145\ttotal: 26.3s\tremaining: 2m 33s\n",
      "146:\tlearn: 0.8203669\ttotal: 26.5s\tremaining: 2m 33s\n",
      "147:\tlearn: 0.8197865\ttotal: 26.6s\tremaining: 2m 33s\n",
      "148:\tlearn: 0.8192783\ttotal: 26.8s\tremaining: 2m 33s\n",
      "149:\tlearn: 0.8186056\ttotal: 27s\tremaining: 2m 33s\n",
      "150:\tlearn: 0.8180419\ttotal: 27.2s\tremaining: 2m 32s\n",
      "151:\tlearn: 0.8171540\ttotal: 27.4s\tremaining: 2m 32s\n",
      "152:\tlearn: 0.8165499\ttotal: 27.5s\tremaining: 2m 32s\n",
      "153:\tlearn: 0.8160230\ttotal: 27.7s\tremaining: 2m 32s\n",
      "154:\tlearn: 0.8155176\ttotal: 27.9s\tremaining: 2m 32s\n",
      "155:\tlearn: 0.8150188\ttotal: 28.1s\tremaining: 2m 31s\n",
      "156:\tlearn: 0.8144897\ttotal: 28.2s\tremaining: 2m 31s\n",
      "157:\tlearn: 0.8138360\ttotal: 28.4s\tremaining: 2m 31s\n",
      "158:\tlearn: 0.8131174\ttotal: 28.6s\tremaining: 2m 31s\n",
      "159:\tlearn: 0.8123417\ttotal: 28.8s\tremaining: 2m 30s\n",
      "160:\tlearn: 0.8117964\ttotal: 29s\tremaining: 2m 30s\n",
      "161:\tlearn: 0.8111937\ttotal: 29.2s\tremaining: 2m 30s\n",
      "162:\tlearn: 0.8105806\ttotal: 29.4s\tremaining: 2m 30s\n",
      "163:\tlearn: 0.8101527\ttotal: 29.6s\tremaining: 2m 30s\n",
      "164:\tlearn: 0.8096502\ttotal: 29.8s\tremaining: 2m 30s\n",
      "165:\tlearn: 0.8090793\ttotal: 30s\tremaining: 2m 30s\n",
      "166:\tlearn: 0.8086097\ttotal: 30.2s\tremaining: 2m 30s\n",
      "167:\tlearn: 0.8081421\ttotal: 30.4s\tremaining: 2m 30s\n",
      "168:\tlearn: 0.8075992\ttotal: 30.6s\tremaining: 2m 30s\n",
      "169:\tlearn: 0.8070319\ttotal: 30.8s\tremaining: 2m 30s\n",
      "170:\tlearn: 0.8066439\ttotal: 31s\tremaining: 2m 30s\n",
      "171:\tlearn: 0.8061703\ttotal: 31.2s\tremaining: 2m 30s\n",
      "172:\tlearn: 0.8054750\ttotal: 31.4s\tremaining: 2m 30s\n",
      "173:\tlearn: 0.8049549\ttotal: 31.6s\tremaining: 2m 30s\n",
      "174:\tlearn: 0.8044250\ttotal: 31.8s\tremaining: 2m 30s\n",
      "175:\tlearn: 0.8038691\ttotal: 32s\tremaining: 2m 29s\n",
      "176:\tlearn: 0.8033697\ttotal: 32.2s\tremaining: 2m 29s\n",
      "177:\tlearn: 0.8028890\ttotal: 32.4s\tremaining: 2m 29s\n",
      "178:\tlearn: 0.8024226\ttotal: 32.6s\tremaining: 2m 29s\n",
      "179:\tlearn: 0.8018892\ttotal: 32.8s\tremaining: 2m 29s\n",
      "180:\tlearn: 0.8014483\ttotal: 32.9s\tremaining: 2m 29s\n",
      "181:\tlearn: 0.8008307\ttotal: 33.1s\tremaining: 2m 28s\n",
      "182:\tlearn: 0.8003907\ttotal: 33.3s\tremaining: 2m 28s\n",
      "183:\tlearn: 0.7999709\ttotal: 33.5s\tremaining: 2m 28s\n",
      "184:\tlearn: 0.7995072\ttotal: 33.6s\tremaining: 2m 28s\n",
      "185:\tlearn: 0.7991193\ttotal: 33.8s\tremaining: 2m 27s\n",
      "186:\tlearn: 0.7985775\ttotal: 34s\tremaining: 2m 27s\n",
      "187:\tlearn: 0.7981488\ttotal: 34.2s\tremaining: 2m 27s\n",
      "188:\tlearn: 0.7978096\ttotal: 34.3s\tremaining: 2m 27s\n",
      "189:\tlearn: 0.7973350\ttotal: 34.5s\tremaining: 2m 27s\n",
      "190:\tlearn: 0.7969578\ttotal: 34.7s\tremaining: 2m 26s\n",
      "191:\tlearn: 0.7965621\ttotal: 34.8s\tremaining: 2m 26s\n",
      "192:\tlearn: 0.7962574\ttotal: 35s\tremaining: 2m 26s\n",
      "193:\tlearn: 0.7956801\ttotal: 35.2s\tremaining: 2m 26s\n",
      "194:\tlearn: 0.7951617\ttotal: 35.4s\tremaining: 2m 26s\n",
      "195:\tlearn: 0.7945826\ttotal: 35.6s\tremaining: 2m 25s\n",
      "196:\tlearn: 0.7942761\ttotal: 35.8s\tremaining: 2m 25s\n",
      "197:\tlearn: 0.7939239\ttotal: 35.9s\tremaining: 2m 25s\n",
      "198:\tlearn: 0.7934669\ttotal: 36.1s\tremaining: 2m 25s\n",
      "199:\tlearn: 0.7930162\ttotal: 36.3s\tremaining: 2m 25s\n",
      "200:\tlearn: 0.7925437\ttotal: 36.5s\tremaining: 2m 24s\n",
      "201:\tlearn: 0.7921513\ttotal: 36.6s\tremaining: 2m 24s\n",
      "202:\tlearn: 0.7918022\ttotal: 36.8s\tremaining: 2m 24s\n",
      "203:\tlearn: 0.7914245\ttotal: 37s\tremaining: 2m 24s\n",
      "204:\tlearn: 0.7909367\ttotal: 37.2s\tremaining: 2m 24s\n",
      "205:\tlearn: 0.7905281\ttotal: 37.4s\tremaining: 2m 23s\n",
      "206:\tlearn: 0.7901975\ttotal: 37.5s\tremaining: 2m 23s\n",
      "207:\tlearn: 0.7897691\ttotal: 37.7s\tremaining: 2m 23s\n",
      "208:\tlearn: 0.7893925\ttotal: 37.9s\tremaining: 2m 23s\n",
      "209:\tlearn: 0.7891952\ttotal: 38.1s\tremaining: 2m 23s\n",
      "210:\tlearn: 0.7887215\ttotal: 38.3s\tremaining: 2m 23s\n",
      "211:\tlearn: 0.7883098\ttotal: 38.5s\tremaining: 2m 23s\n",
      "212:\tlearn: 0.7880191\ttotal: 38.7s\tremaining: 2m 22s\n",
      "213:\tlearn: 0.7876401\ttotal: 38.8s\tremaining: 2m 22s\n",
      "214:\tlearn: 0.7873714\ttotal: 39s\tremaining: 2m 22s\n",
      "215:\tlearn: 0.7869723\ttotal: 39.2s\tremaining: 2m 22s\n",
      "216:\tlearn: 0.7864093\ttotal: 39.4s\tremaining: 2m 22s\n",
      "217:\tlearn: 0.7859505\ttotal: 39.6s\tremaining: 2m 21s\n",
      "218:\tlearn: 0.7854695\ttotal: 39.8s\tremaining: 2m 21s\n",
      "219:\tlearn: 0.7850541\ttotal: 39.9s\tremaining: 2m 21s\n",
      "220:\tlearn: 0.7846186\ttotal: 40.1s\tremaining: 2m 21s\n",
      "221:\tlearn: 0.7841286\ttotal: 40.3s\tremaining: 2m 21s\n",
      "222:\tlearn: 0.7836880\ttotal: 40.4s\tremaining: 2m 20s\n",
      "223:\tlearn: 0.7833424\ttotal: 40.6s\tremaining: 2m 20s\n",
      "224:\tlearn: 0.7830219\ttotal: 40.8s\tremaining: 2m 20s\n",
      "225:\tlearn: 0.7827268\ttotal: 41s\tremaining: 2m 20s\n",
      "226:\tlearn: 0.7824153\ttotal: 41.1s\tremaining: 2m 20s\n",
      "227:\tlearn: 0.7820954\ttotal: 41.3s\tremaining: 2m 19s\n",
      "228:\tlearn: 0.7816970\ttotal: 41.5s\tremaining: 2m 19s\n",
      "229:\tlearn: 0.7813893\ttotal: 41.7s\tremaining: 2m 19s\n",
      "230:\tlearn: 0.7809795\ttotal: 41.9s\tremaining: 2m 19s\n",
      "231:\tlearn: 0.7806587\ttotal: 42.1s\tremaining: 2m 19s\n",
      "232:\tlearn: 0.7802007\ttotal: 42.2s\tremaining: 2m 19s\n",
      "233:\tlearn: 0.7797901\ttotal: 42.4s\tremaining: 2m 18s\n",
      "234:\tlearn: 0.7793870\ttotal: 42.6s\tremaining: 2m 18s\n",
      "235:\tlearn: 0.7790869\ttotal: 42.8s\tremaining: 2m 18s\n",
      "236:\tlearn: 0.7787694\ttotal: 43s\tremaining: 2m 18s\n",
      "237:\tlearn: 0.7784667\ttotal: 43.1s\tremaining: 2m 18s\n",
      "238:\tlearn: 0.7781929\ttotal: 43.3s\tremaining: 2m 17s\n",
      "239:\tlearn: 0.7777973\ttotal: 43.5s\tremaining: 2m 17s\n",
      "240:\tlearn: 0.7774872\ttotal: 43.7s\tremaining: 2m 17s\n",
      "241:\tlearn: 0.7772557\ttotal: 43.8s\tremaining: 2m 17s\n",
      "242:\tlearn: 0.7768749\ttotal: 44s\tremaining: 2m 17s\n",
      "243:\tlearn: 0.7765706\ttotal: 44.2s\tremaining: 2m 16s\n",
      "244:\tlearn: 0.7762905\ttotal: 44.4s\tremaining: 2m 16s\n",
      "245:\tlearn: 0.7760356\ttotal: 44.5s\tremaining: 2m 16s\n",
      "246:\tlearn: 0.7756103\ttotal: 44.7s\tremaining: 2m 16s\n",
      "247:\tlearn: 0.7753063\ttotal: 44.9s\tremaining: 2m 16s\n",
      "248:\tlearn: 0.7749805\ttotal: 45.1s\tremaining: 2m 15s\n",
      "249:\tlearn: 0.7747306\ttotal: 45.3s\tremaining: 2m 15s\n",
      "250:\tlearn: 0.7743393\ttotal: 45.5s\tremaining: 2m 15s\n",
      "251:\tlearn: 0.7740421\ttotal: 45.6s\tremaining: 2m 15s\n",
      "252:\tlearn: 0.7737780\ttotal: 45.8s\tremaining: 2m 15s\n",
      "253:\tlearn: 0.7735165\ttotal: 46s\tremaining: 2m 15s\n",
      "254:\tlearn: 0.7732424\ttotal: 46.2s\tremaining: 2m 14s\n",
      "255:\tlearn: 0.7729941\ttotal: 46.3s\tremaining: 2m 14s\n",
      "256:\tlearn: 0.7727013\ttotal: 46.5s\tremaining: 2m 14s\n",
      "257:\tlearn: 0.7723989\ttotal: 46.7s\tremaining: 2m 14s\n",
      "258:\tlearn: 0.7719997\ttotal: 46.9s\tremaining: 2m 14s\n",
      "259:\tlearn: 0.7716294\ttotal: 47s\tremaining: 2m 13s\n",
      "260:\tlearn: 0.7712923\ttotal: 47.2s\tremaining: 2m 13s\n",
      "261:\tlearn: 0.7710630\ttotal: 47.4s\tremaining: 2m 13s\n",
      "262:\tlearn: 0.7709233\ttotal: 47.6s\tremaining: 2m 13s\n",
      "263:\tlearn: 0.7706304\ttotal: 47.8s\tremaining: 2m 13s\n",
      "264:\tlearn: 0.7703657\ttotal: 47.9s\tremaining: 2m 12s\n",
      "265:\tlearn: 0.7701396\ttotal: 48.1s\tremaining: 2m 12s\n",
      "266:\tlearn: 0.7697324\ttotal: 48.3s\tremaining: 2m 12s\n",
      "267:\tlearn: 0.7692378\ttotal: 48.5s\tremaining: 2m 12s\n",
      "268:\tlearn: 0.7689849\ttotal: 48.7s\tremaining: 2m 12s\n",
      "269:\tlearn: 0.7687641\ttotal: 48.8s\tremaining: 2m 12s\n",
      "270:\tlearn: 0.7684430\ttotal: 49s\tremaining: 2m 11s\n",
      "271:\tlearn: 0.7681365\ttotal: 49.2s\tremaining: 2m 11s\n",
      "272:\tlearn: 0.7677391\ttotal: 49.4s\tremaining: 2m 11s\n",
      "273:\tlearn: 0.7673693\ttotal: 49.5s\tremaining: 2m 11s\n",
      "274:\tlearn: 0.7671270\ttotal: 49.7s\tremaining: 2m 11s\n",
      "275:\tlearn: 0.7668597\ttotal: 49.9s\tremaining: 2m 10s\n",
      "276:\tlearn: 0.7665316\ttotal: 50.1s\tremaining: 2m 10s\n",
      "277:\tlearn: 0.7663179\ttotal: 50.3s\tremaining: 2m 10s\n",
      "278:\tlearn: 0.7659684\ttotal: 50.5s\tremaining: 2m 10s\n",
      "279:\tlearn: 0.7656248\ttotal: 50.6s\tremaining: 2m 10s\n",
      "280:\tlearn: 0.7653917\ttotal: 50.8s\tremaining: 2m 10s\n",
      "281:\tlearn: 0.7649386\ttotal: 51s\tremaining: 2m 9s\n",
      "282:\tlearn: 0.7646328\ttotal: 51.2s\tremaining: 2m 9s\n",
      "283:\tlearn: 0.7643904\ttotal: 51.4s\tremaining: 2m 9s\n",
      "284:\tlearn: 0.7641260\ttotal: 51.6s\tremaining: 2m 9s\n",
      "285:\tlearn: 0.7638868\ttotal: 51.8s\tremaining: 2m 9s\n",
      "286:\tlearn: 0.7636665\ttotal: 52s\tremaining: 2m 9s\n",
      "287:\tlearn: 0.7633811\ttotal: 52.2s\tremaining: 2m 8s\n",
      "288:\tlearn: 0.7631417\ttotal: 52.3s\tremaining: 2m 8s\n",
      "289:\tlearn: 0.7628796\ttotal: 52.5s\tremaining: 2m 8s\n",
      "290:\tlearn: 0.7626485\ttotal: 52.7s\tremaining: 2m 8s\n",
      "291:\tlearn: 0.7623959\ttotal: 52.9s\tremaining: 2m 8s\n",
      "292:\tlearn: 0.7621202\ttotal: 53.1s\tremaining: 2m 8s\n",
      "293:\tlearn: 0.7618852\ttotal: 53.3s\tremaining: 2m 8s\n",
      "294:\tlearn: 0.7616194\ttotal: 53.5s\tremaining: 2m 7s\n",
      "295:\tlearn: 0.7611417\ttotal: 53.7s\tremaining: 2m 7s\n",
      "296:\tlearn: 0.7606279\ttotal: 53.9s\tremaining: 2m 7s\n",
      "297:\tlearn: 0.7604169\ttotal: 54.1s\tremaining: 2m 7s\n",
      "298:\tlearn: 0.7601170\ttotal: 54.3s\tremaining: 2m 7s\n",
      "299:\tlearn: 0.7598042\ttotal: 54.5s\tremaining: 2m 7s\n",
      "300:\tlearn: 0.7595912\ttotal: 54.7s\tremaining: 2m 6s\n",
      "301:\tlearn: 0.7592066\ttotal: 54.8s\tremaining: 2m 6s\n",
      "302:\tlearn: 0.7589286\ttotal: 55s\tremaining: 2m 6s\n",
      "303:\tlearn: 0.7586611\ttotal: 55.2s\tremaining: 2m 6s\n",
      "304:\tlearn: 0.7584111\ttotal: 55.4s\tremaining: 2m 6s\n",
      "305:\tlearn: 0.7581466\ttotal: 55.6s\tremaining: 2m 6s\n",
      "306:\tlearn: 0.7578962\ttotal: 55.8s\tremaining: 2m 5s\n",
      "307:\tlearn: 0.7576775\ttotal: 56s\tremaining: 2m 5s\n",
      "308:\tlearn: 0.7574470\ttotal: 56.2s\tremaining: 2m 5s\n",
      "309:\tlearn: 0.7571815\ttotal: 56.3s\tremaining: 2m 5s\n",
      "310:\tlearn: 0.7568762\ttotal: 56.5s\tremaining: 2m 5s\n",
      "311:\tlearn: 0.7566030\ttotal: 56.7s\tremaining: 2m 5s\n",
      "312:\tlearn: 0.7564417\ttotal: 56.9s\tremaining: 2m 4s\n",
      "313:\tlearn: 0.7561408\ttotal: 57.1s\tremaining: 2m 4s\n",
      "314:\tlearn: 0.7559314\ttotal: 57.3s\tremaining: 2m 4s\n",
      "315:\tlearn: 0.7555872\ttotal: 57.5s\tremaining: 2m 4s\n",
      "316:\tlearn: 0.7553391\ttotal: 57.7s\tremaining: 2m 4s\n",
      "317:\tlearn: 0.7551622\ttotal: 57.9s\tremaining: 2m 4s\n",
      "318:\tlearn: 0.7549410\ttotal: 58.1s\tremaining: 2m 3s\n",
      "319:\tlearn: 0.7547392\ttotal: 58.3s\tremaining: 2m 3s\n",
      "320:\tlearn: 0.7544710\ttotal: 58.4s\tremaining: 2m 3s\n",
      "321:\tlearn: 0.7541900\ttotal: 58.6s\tremaining: 2m 3s\n",
      "322:\tlearn: 0.7539496\ttotal: 58.8s\tremaining: 2m 3s\n",
      "323:\tlearn: 0.7537150\ttotal: 59s\tremaining: 2m 3s\n",
      "324:\tlearn: 0.7535351\ttotal: 59.1s\tremaining: 2m 2s\n",
      "325:\tlearn: 0.7532592\ttotal: 59.3s\tremaining: 2m 2s\n",
      "326:\tlearn: 0.7530549\ttotal: 59.5s\tremaining: 2m 2s\n",
      "327:\tlearn: 0.7528558\ttotal: 59.7s\tremaining: 2m 2s\n",
      "328:\tlearn: 0.7526510\ttotal: 59.9s\tremaining: 2m 2s\n",
      "329:\tlearn: 0.7524023\ttotal: 1m\tremaining: 2m 1s\n",
      "330:\tlearn: 0.7522119\ttotal: 1m\tremaining: 2m 1s\n",
      "331:\tlearn: 0.7520058\ttotal: 1m\tremaining: 2m 1s\n",
      "332:\tlearn: 0.7516212\ttotal: 1m\tremaining: 2m 1s\n",
      "333:\tlearn: 0.7514689\ttotal: 1m\tremaining: 2m 1s\n",
      "334:\tlearn: 0.7511124\ttotal: 1m\tremaining: 2m\n",
      "335:\tlearn: 0.7508902\ttotal: 1m 1s\tremaining: 2m\n",
      "336:\tlearn: 0.7506769\ttotal: 1m 1s\tremaining: 2m\n",
      "337:\tlearn: 0.7503710\ttotal: 1m 1s\tremaining: 2m\n",
      "338:\tlearn: 0.7501350\ttotal: 1m 1s\tremaining: 2m\n",
      "339:\tlearn: 0.7499741\ttotal: 1m 1s\tremaining: 1m 59s\n",
      "340:\tlearn: 0.7497024\ttotal: 1m 1s\tremaining: 1m 59s\n",
      "341:\tlearn: 0.7495439\ttotal: 1m 2s\tremaining: 1m 59s\n",
      "342:\tlearn: 0.7494505\ttotal: 1m 2s\tremaining: 1m 59s\n",
      "343:\tlearn: 0.7492021\ttotal: 1m 2s\tremaining: 1m 59s\n",
      "344:\tlearn: 0.7490311\ttotal: 1m 2s\tremaining: 1m 58s\n",
      "345:\tlearn: 0.7488795\ttotal: 1m 2s\tremaining: 1m 58s\n",
      "346:\tlearn: 0.7487018\ttotal: 1m 3s\tremaining: 1m 58s\n",
      "347:\tlearn: 0.7485428\ttotal: 1m 3s\tremaining: 1m 58s\n",
      "348:\tlearn: 0.7482413\ttotal: 1m 3s\tremaining: 1m 58s\n",
      "349:\tlearn: 0.7481500\ttotal: 1m 3s\tremaining: 1m 58s\n",
      "350:\tlearn: 0.7477794\ttotal: 1m 3s\tremaining: 1m 57s\n",
      "351:\tlearn: 0.7474919\ttotal: 1m 3s\tremaining: 1m 57s\n",
      "352:\tlearn: 0.7472325\ttotal: 1m 4s\tremaining: 1m 57s\n",
      "353:\tlearn: 0.7470187\ttotal: 1m 4s\tremaining: 1m 57s\n",
      "354:\tlearn: 0.7468979\ttotal: 1m 4s\tremaining: 1m 57s\n",
      "355:\tlearn: 0.7467824\ttotal: 1m 4s\tremaining: 1m 56s\n",
      "356:\tlearn: 0.7465836\ttotal: 1m 4s\tremaining: 1m 56s\n",
      "357:\tlearn: 0.7462714\ttotal: 1m 4s\tremaining: 1m 56s\n",
      "358:\tlearn: 0.7461138\ttotal: 1m 5s\tremaining: 1m 56s\n",
      "359:\tlearn: 0.7458103\ttotal: 1m 5s\tremaining: 1m 56s\n",
      "360:\tlearn: 0.7456166\ttotal: 1m 5s\tremaining: 1m 55s\n",
      "361:\tlearn: 0.7454284\ttotal: 1m 5s\tremaining: 1m 55s\n",
      "362:\tlearn: 0.7452516\ttotal: 1m 5s\tremaining: 1m 55s\n",
      "363:\tlearn: 0.7451142\ttotal: 1m 5s\tremaining: 1m 55s\n",
      "364:\tlearn: 0.7449440\ttotal: 1m 6s\tremaining: 1m 55s\n",
      "365:\tlearn: 0.7447469\ttotal: 1m 6s\tremaining: 1m 54s\n",
      "366:\tlearn: 0.7445341\ttotal: 1m 6s\tremaining: 1m 54s\n",
      "367:\tlearn: 0.7442840\ttotal: 1m 6s\tremaining: 1m 54s\n",
      "368:\tlearn: 0.7438969\ttotal: 1m 6s\tremaining: 1m 54s\n",
      "369:\tlearn: 0.7437340\ttotal: 1m 7s\tremaining: 1m 54s\n",
      "370:\tlearn: 0.7435484\ttotal: 1m 7s\tremaining: 1m 53s\n",
      "371:\tlearn: 0.7433967\ttotal: 1m 7s\tremaining: 1m 53s\n",
      "372:\tlearn: 0.7432055\ttotal: 1m 7s\tremaining: 1m 53s\n",
      "373:\tlearn: 0.7430178\ttotal: 1m 7s\tremaining: 1m 53s\n",
      "374:\tlearn: 0.7428359\ttotal: 1m 7s\tremaining: 1m 53s\n",
      "375:\tlearn: 0.7426658\ttotal: 1m 8s\tremaining: 1m 53s\n",
      "376:\tlearn: 0.7425433\ttotal: 1m 8s\tremaining: 1m 52s\n",
      "377:\tlearn: 0.7424140\ttotal: 1m 8s\tremaining: 1m 52s\n",
      "378:\tlearn: 0.7422573\ttotal: 1m 8s\tremaining: 1m 52s\n",
      "379:\tlearn: 0.7420563\ttotal: 1m 8s\tremaining: 1m 52s\n",
      "380:\tlearn: 0.7419071\ttotal: 1m 9s\tremaining: 1m 52s\n",
      "381:\tlearn: 0.7417571\ttotal: 1m 9s\tremaining: 1m 51s\n",
      "382:\tlearn: 0.7416366\ttotal: 1m 9s\tremaining: 1m 51s\n",
      "383:\tlearn: 0.7414909\ttotal: 1m 9s\tremaining: 1m 51s\n",
      "384:\tlearn: 0.7413392\ttotal: 1m 9s\tremaining: 1m 51s\n",
      "385:\tlearn: 0.7410867\ttotal: 1m 9s\tremaining: 1m 51s\n",
      "386:\tlearn: 0.7408760\ttotal: 1m 10s\tremaining: 1m 51s\n",
      "387:\tlearn: 0.7406982\ttotal: 1m 10s\tremaining: 1m 50s\n",
      "388:\tlearn: 0.7403701\ttotal: 1m 10s\tremaining: 1m 50s\n",
      "389:\tlearn: 0.7402102\ttotal: 1m 10s\tremaining: 1m 50s\n",
      "390:\tlearn: 0.7399715\ttotal: 1m 10s\tremaining: 1m 50s\n",
      "391:\tlearn: 0.7397760\ttotal: 1m 10s\tremaining: 1m 50s\n",
      "392:\tlearn: 0.7395676\ttotal: 1m 11s\tremaining: 1m 49s\n",
      "393:\tlearn: 0.7394596\ttotal: 1m 11s\tremaining: 1m 49s\n",
      "394:\tlearn: 0.7392431\ttotal: 1m 11s\tremaining: 1m 49s\n",
      "395:\tlearn: 0.7390573\ttotal: 1m 11s\tremaining: 1m 49s\n",
      "396:\tlearn: 0.7388910\ttotal: 1m 11s\tremaining: 1m 49s\n",
      "397:\tlearn: 0.7386825\ttotal: 1m 12s\tremaining: 1m 48s\n",
      "398:\tlearn: 0.7384469\ttotal: 1m 12s\tremaining: 1m 48s\n",
      "399:\tlearn: 0.7383116\ttotal: 1m 12s\tremaining: 1m 48s\n",
      "400:\tlearn: 0.7380796\ttotal: 1m 12s\tremaining: 1m 48s\n",
      "401:\tlearn: 0.7380011\ttotal: 1m 12s\tremaining: 1m 48s\n",
      "402:\tlearn: 0.7378933\ttotal: 1m 12s\tremaining: 1m 47s\n",
      "403:\tlearn: 0.7377680\ttotal: 1m 13s\tremaining: 1m 47s\n",
      "404:\tlearn: 0.7376354\ttotal: 1m 13s\tremaining: 1m 47s\n",
      "405:\tlearn: 0.7373886\ttotal: 1m 13s\tremaining: 1m 47s\n",
      "406:\tlearn: 0.7371519\ttotal: 1m 13s\tremaining: 1m 47s\n",
      "407:\tlearn: 0.7369605\ttotal: 1m 13s\tremaining: 1m 47s\n",
      "408:\tlearn: 0.7367862\ttotal: 1m 13s\tremaining: 1m 46s\n",
      "409:\tlearn: 0.7366721\ttotal: 1m 14s\tremaining: 1m 46s\n",
      "410:\tlearn: 0.7364940\ttotal: 1m 14s\tremaining: 1m 46s\n",
      "411:\tlearn: 0.7363488\ttotal: 1m 14s\tremaining: 1m 46s\n",
      "412:\tlearn: 0.7361676\ttotal: 1m 14s\tremaining: 1m 46s\n",
      "413:\tlearn: 0.7360117\ttotal: 1m 14s\tremaining: 1m 45s\n",
      "414:\tlearn: 0.7358248\ttotal: 1m 15s\tremaining: 1m 45s\n",
      "415:\tlearn: 0.7354323\ttotal: 1m 15s\tremaining: 1m 45s\n",
      "416:\tlearn: 0.7352414\ttotal: 1m 15s\tremaining: 1m 45s\n",
      "417:\tlearn: 0.7351243\ttotal: 1m 15s\tremaining: 1m 45s\n",
      "418:\tlearn: 0.7349962\ttotal: 1m 15s\tremaining: 1m 45s\n",
      "419:\tlearn: 0.7347918\ttotal: 1m 15s\tremaining: 1m 44s\n",
      "420:\tlearn: 0.7344398\ttotal: 1m 16s\tremaining: 1m 44s\n",
      "421:\tlearn: 0.7342860\ttotal: 1m 16s\tremaining: 1m 44s\n",
      "422:\tlearn: 0.7341037\ttotal: 1m 16s\tremaining: 1m 44s\n",
      "423:\tlearn: 0.7339379\ttotal: 1m 16s\tremaining: 1m 44s\n",
      "424:\tlearn: 0.7337440\ttotal: 1m 16s\tremaining: 1m 43s\n",
      "425:\tlearn: 0.7336117\ttotal: 1m 17s\tremaining: 1m 43s\n",
      "426:\tlearn: 0.7333781\ttotal: 1m 17s\tremaining: 1m 43s\n",
      "427:\tlearn: 0.7330639\ttotal: 1m 17s\tremaining: 1m 43s\n",
      "428:\tlearn: 0.7328200\ttotal: 1m 17s\tremaining: 1m 43s\n",
      "429:\tlearn: 0.7325851\ttotal: 1m 17s\tremaining: 1m 43s\n",
      "430:\tlearn: 0.7324317\ttotal: 1m 17s\tremaining: 1m 42s\n",
      "431:\tlearn: 0.7322600\ttotal: 1m 18s\tremaining: 1m 42s\n",
      "432:\tlearn: 0.7320790\ttotal: 1m 18s\tremaining: 1m 42s\n",
      "433:\tlearn: 0.7319095\ttotal: 1m 18s\tremaining: 1m 42s\n",
      "434:\tlearn: 0.7317111\ttotal: 1m 18s\tremaining: 1m 42s\n",
      "435:\tlearn: 0.7315500\ttotal: 1m 18s\tremaining: 1m 41s\n",
      "436:\tlearn: 0.7314407\ttotal: 1m 18s\tremaining: 1m 41s\n",
      "437:\tlearn: 0.7313254\ttotal: 1m 19s\tremaining: 1m 41s\n",
      "438:\tlearn: 0.7312008\ttotal: 1m 19s\tremaining: 1m 41s\n",
      "439:\tlearn: 0.7309493\ttotal: 1m 19s\tremaining: 1m 41s\n",
      "440:\tlearn: 0.7308065\ttotal: 1m 19s\tremaining: 1m 41s\n",
      "441:\tlearn: 0.7307193\ttotal: 1m 19s\tremaining: 1m 40s\n",
      "442:\tlearn: 0.7305411\ttotal: 1m 20s\tremaining: 1m 40s\n",
      "443:\tlearn: 0.7303759\ttotal: 1m 20s\tremaining: 1m 40s\n",
      "444:\tlearn: 0.7301566\ttotal: 1m 20s\tremaining: 1m 40s\n",
      "445:\tlearn: 0.7299307\ttotal: 1m 20s\tremaining: 1m 40s\n",
      "446:\tlearn: 0.7297860\ttotal: 1m 20s\tremaining: 1m 39s\n",
      "447:\tlearn: 0.7296778\ttotal: 1m 20s\tremaining: 1m 39s\n",
      "448:\tlearn: 0.7294823\ttotal: 1m 21s\tremaining: 1m 39s\n",
      "449:\tlearn: 0.7293504\ttotal: 1m 21s\tremaining: 1m 39s\n",
      "450:\tlearn: 0.7291952\ttotal: 1m 21s\tremaining: 1m 39s\n",
      "451:\tlearn: 0.7289416\ttotal: 1m 21s\tremaining: 1m 38s\n",
      "452:\tlearn: 0.7288562\ttotal: 1m 21s\tremaining: 1m 38s\n",
      "453:\tlearn: 0.7287685\ttotal: 1m 21s\tremaining: 1m 38s\n",
      "454:\tlearn: 0.7285672\ttotal: 1m 22s\tremaining: 1m 38s\n",
      "455:\tlearn: 0.7283787\ttotal: 1m 22s\tremaining: 1m 38s\n",
      "456:\tlearn: 0.7281310\ttotal: 1m 22s\tremaining: 1m 38s\n",
      "457:\tlearn: 0.7279345\ttotal: 1m 22s\tremaining: 1m 37s\n",
      "458:\tlearn: 0.7278520\ttotal: 1m 22s\tremaining: 1m 37s\n",
      "459:\tlearn: 0.7276295\ttotal: 1m 23s\tremaining: 1m 37s\n",
      "460:\tlearn: 0.7275375\ttotal: 1m 23s\tremaining: 1m 37s\n",
      "461:\tlearn: 0.7274250\ttotal: 1m 23s\tremaining: 1m 37s\n",
      "462:\tlearn: 0.7271928\ttotal: 1m 23s\tremaining: 1m 36s\n",
      "463:\tlearn: 0.7271260\ttotal: 1m 23s\tremaining: 1m 36s\n",
      "464:\tlearn: 0.7269409\ttotal: 1m 23s\tremaining: 1m 36s\n",
      "465:\tlearn: 0.7268321\ttotal: 1m 24s\tremaining: 1m 36s\n",
      "466:\tlearn: 0.7267014\ttotal: 1m 24s\tremaining: 1m 36s\n",
      "467:\tlearn: 0.7265350\ttotal: 1m 24s\tremaining: 1m 36s\n",
      "468:\tlearn: 0.7264053\ttotal: 1m 24s\tremaining: 1m 35s\n",
      "469:\tlearn: 0.7263282\ttotal: 1m 24s\tremaining: 1m 35s\n",
      "470:\tlearn: 0.7262216\ttotal: 1m 24s\tremaining: 1m 35s\n",
      "471:\tlearn: 0.7260386\ttotal: 1m 25s\tremaining: 1m 35s\n",
      "472:\tlearn: 0.7258166\ttotal: 1m 25s\tremaining: 1m 35s\n",
      "473:\tlearn: 0.7256238\ttotal: 1m 25s\tremaining: 1m 34s\n",
      "474:\tlearn: 0.7254849\ttotal: 1m 25s\tremaining: 1m 34s\n",
      "475:\tlearn: 0.7252802\ttotal: 1m 25s\tremaining: 1m 34s\n",
      "476:\tlearn: 0.7251169\ttotal: 1m 26s\tremaining: 1m 34s\n",
      "477:\tlearn: 0.7250405\ttotal: 1m 26s\tremaining: 1m 34s\n",
      "478:\tlearn: 0.7248004\ttotal: 1m 26s\tremaining: 1m 33s\n",
      "479:\tlearn: 0.7247305\ttotal: 1m 26s\tremaining: 1m 33s\n",
      "480:\tlearn: 0.7246478\ttotal: 1m 26s\tremaining: 1m 33s\n",
      "481:\tlearn: 0.7245208\ttotal: 1m 26s\tremaining: 1m 33s\n",
      "482:\tlearn: 0.7244412\ttotal: 1m 27s\tremaining: 1m 33s\n",
      "483:\tlearn: 0.7243205\ttotal: 1m 27s\tremaining: 1m 33s\n",
      "484:\tlearn: 0.7241684\ttotal: 1m 27s\tremaining: 1m 32s\n",
      "485:\tlearn: 0.7239157\ttotal: 1m 27s\tremaining: 1m 32s\n",
      "486:\tlearn: 0.7237681\ttotal: 1m 27s\tremaining: 1m 32s\n",
      "487:\tlearn: 0.7236426\ttotal: 1m 28s\tremaining: 1m 32s\n",
      "488:\tlearn: 0.7234777\ttotal: 1m 28s\tremaining: 1m 32s\n",
      "489:\tlearn: 0.7233992\ttotal: 1m 28s\tremaining: 1m 31s\n",
      "490:\tlearn: 0.7233417\ttotal: 1m 28s\tremaining: 1m 31s\n",
      "491:\tlearn: 0.7231163\ttotal: 1m 28s\tremaining: 1m 31s\n",
      "492:\tlearn: 0.7230040\ttotal: 1m 28s\tremaining: 1m 31s\n",
      "493:\tlearn: 0.7228685\ttotal: 1m 29s\tremaining: 1m 31s\n",
      "494:\tlearn: 0.7226347\ttotal: 1m 29s\tremaining: 1m 31s\n",
      "495:\tlearn: 0.7224230\ttotal: 1m 29s\tremaining: 1m 30s\n",
      "496:\tlearn: 0.7222945\ttotal: 1m 29s\tremaining: 1m 30s\n",
      "497:\tlearn: 0.7222249\ttotal: 1m 29s\tremaining: 1m 30s\n",
      "498:\tlearn: 0.7221213\ttotal: 1m 29s\tremaining: 1m 30s\n",
      "499:\tlearn: 0.7219950\ttotal: 1m 30s\tremaining: 1m 30s\n",
      "500:\tlearn: 0.7218311\ttotal: 1m 30s\tremaining: 1m 29s\n",
      "501:\tlearn: 0.7217447\ttotal: 1m 30s\tremaining: 1m 29s\n",
      "502:\tlearn: 0.7216353\ttotal: 1m 30s\tremaining: 1m 29s\n",
      "503:\tlearn: 0.7214768\ttotal: 1m 30s\tremaining: 1m 29s\n",
      "504:\tlearn: 0.7213142\ttotal: 1m 31s\tremaining: 1m 29s\n",
      "505:\tlearn: 0.7211912\ttotal: 1m 31s\tremaining: 1m 29s\n",
      "506:\tlearn: 0.7210805\ttotal: 1m 31s\tremaining: 1m 28s\n",
      "507:\tlearn: 0.7209109\ttotal: 1m 31s\tremaining: 1m 28s\n",
      "508:\tlearn: 0.7208126\ttotal: 1m 31s\tremaining: 1m 28s\n",
      "509:\tlearn: 0.7205741\ttotal: 1m 31s\tremaining: 1m 28s\n",
      "510:\tlearn: 0.7204384\ttotal: 1m 32s\tremaining: 1m 28s\n",
      "511:\tlearn: 0.7202192\ttotal: 1m 32s\tremaining: 1m 27s\n",
      "512:\tlearn: 0.7200919\ttotal: 1m 32s\tremaining: 1m 27s\n",
      "513:\tlearn: 0.7199006\ttotal: 1m 32s\tremaining: 1m 27s\n",
      "514:\tlearn: 0.7197922\ttotal: 1m 32s\tremaining: 1m 27s\n",
      "515:\tlearn: 0.7196124\ttotal: 1m 32s\tremaining: 1m 27s\n",
      "516:\tlearn: 0.7194991\ttotal: 1m 33s\tremaining: 1m 26s\n",
      "517:\tlearn: 0.7193323\ttotal: 1m 33s\tremaining: 1m 26s\n",
      "518:\tlearn: 0.7192436\ttotal: 1m 33s\tremaining: 1m 26s\n",
      "519:\tlearn: 0.7191504\ttotal: 1m 33s\tremaining: 1m 26s\n",
      "520:\tlearn: 0.7190587\ttotal: 1m 33s\tremaining: 1m 26s\n",
      "521:\tlearn: 0.7189744\ttotal: 1m 33s\tremaining: 1m 26s\n",
      "522:\tlearn: 0.7189077\ttotal: 1m 34s\tremaining: 1m 25s\n",
      "523:\tlearn: 0.7188478\ttotal: 1m 34s\tremaining: 1m 25s\n",
      "524:\tlearn: 0.7187592\ttotal: 1m 34s\tremaining: 1m 25s\n",
      "525:\tlearn: 0.7187166\ttotal: 1m 34s\tremaining: 1m 25s\n",
      "526:\tlearn: 0.7184922\ttotal: 1m 34s\tremaining: 1m 25s\n",
      "527:\tlearn: 0.7183439\ttotal: 1m 35s\tremaining: 1m 24s\n",
      "528:\tlearn: 0.7182673\ttotal: 1m 35s\tremaining: 1m 24s\n",
      "529:\tlearn: 0.7182104\ttotal: 1m 35s\tremaining: 1m 24s\n",
      "530:\tlearn: 0.7181403\ttotal: 1m 35s\tremaining: 1m 24s\n",
      "531:\tlearn: 0.7179895\ttotal: 1m 35s\tremaining: 1m 24s\n",
      "532:\tlearn: 0.7178185\ttotal: 1m 35s\tremaining: 1m 24s\n",
      "533:\tlearn: 0.7177279\ttotal: 1m 36s\tremaining: 1m 23s\n",
      "534:\tlearn: 0.7175752\ttotal: 1m 36s\tremaining: 1m 23s\n",
      "535:\tlearn: 0.7174118\ttotal: 1m 36s\tremaining: 1m 23s\n",
      "536:\tlearn: 0.7173739\ttotal: 1m 36s\tremaining: 1m 23s\n",
      "537:\tlearn: 0.7171521\ttotal: 1m 36s\tremaining: 1m 23s\n",
      "538:\tlearn: 0.7169776\ttotal: 1m 36s\tremaining: 1m 22s\n",
      "539:\tlearn: 0.7168324\ttotal: 1m 37s\tremaining: 1m 22s\n",
      "540:\tlearn: 0.7167287\ttotal: 1m 37s\tremaining: 1m 22s\n",
      "541:\tlearn: 0.7166116\ttotal: 1m 37s\tremaining: 1m 22s\n",
      "542:\tlearn: 0.7165089\ttotal: 1m 37s\tremaining: 1m 22s\n",
      "543:\tlearn: 0.7162795\ttotal: 1m 37s\tremaining: 1m 22s\n",
      "544:\tlearn: 0.7161860\ttotal: 1m 38s\tremaining: 1m 21s\n",
      "545:\tlearn: 0.7161400\ttotal: 1m 38s\tremaining: 1m 21s\n",
      "546:\tlearn: 0.7158918\ttotal: 1m 38s\tremaining: 1m 21s\n",
      "547:\tlearn: 0.7158204\ttotal: 1m 38s\tremaining: 1m 21s\n",
      "548:\tlearn: 0.7157568\ttotal: 1m 38s\tremaining: 1m 21s\n",
      "549:\tlearn: 0.7155852\ttotal: 1m 39s\tremaining: 1m 21s\n",
      "550:\tlearn: 0.7154203\ttotal: 1m 39s\tremaining: 1m 20s\n",
      "551:\tlearn: 0.7153047\ttotal: 1m 39s\tremaining: 1m 20s\n",
      "552:\tlearn: 0.7151435\ttotal: 1m 39s\tremaining: 1m 20s\n",
      "553:\tlearn: 0.7150625\ttotal: 1m 39s\tremaining: 1m 20s\n",
      "554:\tlearn: 0.7149907\ttotal: 1m 39s\tremaining: 1m 20s\n",
      "555:\tlearn: 0.7149235\ttotal: 1m 40s\tremaining: 1m 19s\n",
      "556:\tlearn: 0.7148654\ttotal: 1m 40s\tremaining: 1m 19s\n",
      "557:\tlearn: 0.7147128\ttotal: 1m 40s\tremaining: 1m 19s\n",
      "558:\tlearn: 0.7145133\ttotal: 1m 40s\tremaining: 1m 19s\n",
      "559:\tlearn: 0.7143359\ttotal: 1m 40s\tremaining: 1m 19s\n",
      "560:\tlearn: 0.7142405\ttotal: 1m 41s\tremaining: 1m 19s\n",
      "561:\tlearn: 0.7140743\ttotal: 1m 41s\tremaining: 1m 18s\n",
      "562:\tlearn: 0.7140047\ttotal: 1m 41s\tremaining: 1m 18s\n",
      "563:\tlearn: 0.7137239\ttotal: 1m 41s\tremaining: 1m 18s\n",
      "564:\tlearn: 0.7136201\ttotal: 1m 41s\tremaining: 1m 18s\n",
      "565:\tlearn: 0.7135248\ttotal: 1m 42s\tremaining: 1m 18s\n",
      "566:\tlearn: 0.7133817\ttotal: 1m 42s\tremaining: 1m 18s\n",
      "567:\tlearn: 0.7132842\ttotal: 1m 42s\tremaining: 1m 17s\n",
      "568:\tlearn: 0.7131123\ttotal: 1m 42s\tremaining: 1m 17s\n",
      "569:\tlearn: 0.7130663\ttotal: 1m 42s\tremaining: 1m 17s\n",
      "570:\tlearn: 0.7130038\ttotal: 1m 43s\tremaining: 1m 17s\n",
      "571:\tlearn: 0.7129168\ttotal: 1m 43s\tremaining: 1m 17s\n",
      "572:\tlearn: 0.7128132\ttotal: 1m 43s\tremaining: 1m 17s\n",
      "573:\tlearn: 0.7127086\ttotal: 1m 43s\tremaining: 1m 16s\n",
      "574:\tlearn: 0.7126268\ttotal: 1m 43s\tremaining: 1m 16s\n",
      "575:\tlearn: 0.7125437\ttotal: 1m 44s\tremaining: 1m 16s\n",
      "576:\tlearn: 0.7124215\ttotal: 1m 44s\tremaining: 1m 16s\n",
      "577:\tlearn: 0.7123615\ttotal: 1m 44s\tremaining: 1m 16s\n",
      "578:\tlearn: 0.7122547\ttotal: 1m 44s\tremaining: 1m 16s\n",
      "579:\tlearn: 0.7121367\ttotal: 1m 44s\tremaining: 1m 15s\n",
      "580:\tlearn: 0.7121025\ttotal: 1m 44s\tremaining: 1m 15s\n",
      "581:\tlearn: 0.7120345\ttotal: 1m 45s\tremaining: 1m 15s\n",
      "582:\tlearn: 0.7119344\ttotal: 1m 45s\tremaining: 1m 15s\n",
      "583:\tlearn: 0.7118416\ttotal: 1m 45s\tremaining: 1m 15s\n",
      "584:\tlearn: 0.7117433\ttotal: 1m 45s\tremaining: 1m 14s\n",
      "585:\tlearn: 0.7116542\ttotal: 1m 45s\tremaining: 1m 14s\n",
      "586:\tlearn: 0.7115948\ttotal: 1m 46s\tremaining: 1m 14s\n",
      "587:\tlearn: 0.7112877\ttotal: 1m 46s\tremaining: 1m 14s\n",
      "588:\tlearn: 0.7111911\ttotal: 1m 46s\tremaining: 1m 14s\n",
      "589:\tlearn: 0.7110857\ttotal: 1m 46s\tremaining: 1m 14s\n",
      "590:\tlearn: 0.7109810\ttotal: 1m 46s\tremaining: 1m 13s\n",
      "591:\tlearn: 0.7108371\ttotal: 1m 46s\tremaining: 1m 13s\n",
      "592:\tlearn: 0.7107767\ttotal: 1m 47s\tremaining: 1m 13s\n",
      "593:\tlearn: 0.7106429\ttotal: 1m 47s\tremaining: 1m 13s\n",
      "594:\tlearn: 0.7104678\ttotal: 1m 47s\tremaining: 1m 13s\n",
      "595:\tlearn: 0.7103562\ttotal: 1m 47s\tremaining: 1m 12s\n",
      "596:\tlearn: 0.7102346\ttotal: 1m 47s\tremaining: 1m 12s\n",
      "597:\tlearn: 0.7100379\ttotal: 1m 47s\tremaining: 1m 12s\n",
      "598:\tlearn: 0.7099514\ttotal: 1m 48s\tremaining: 1m 12s\n",
      "599:\tlearn: 0.7098338\ttotal: 1m 48s\tremaining: 1m 12s\n",
      "600:\tlearn: 0.7097278\ttotal: 1m 48s\tremaining: 1m 11s\n",
      "601:\tlearn: 0.7096504\ttotal: 1m 48s\tremaining: 1m 11s\n",
      "602:\tlearn: 0.7095741\ttotal: 1m 48s\tremaining: 1m 11s\n",
      "603:\tlearn: 0.7094301\ttotal: 1m 48s\tremaining: 1m 11s\n",
      "604:\tlearn: 0.7093101\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "605:\tlearn: 0.7091909\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "606:\tlearn: 0.7089878\ttotal: 1m 49s\tremaining: 1m 10s\n",
      "607:\tlearn: 0.7089146\ttotal: 1m 49s\tremaining: 1m 10s\n",
      "608:\tlearn: 0.7088339\ttotal: 1m 49s\tremaining: 1m 10s\n",
      "609:\tlearn: 0.7087611\ttotal: 1m 49s\tremaining: 1m 10s\n",
      "610:\tlearn: 0.7086310\ttotal: 1m 50s\tremaining: 1m 10s\n",
      "611:\tlearn: 0.7083453\ttotal: 1m 50s\tremaining: 1m 9s\n",
      "612:\tlearn: 0.7082490\ttotal: 1m 50s\tremaining: 1m 9s\n",
      "613:\tlearn: 0.7081653\ttotal: 1m 50s\tremaining: 1m 9s\n",
      "614:\tlearn: 0.7081275\ttotal: 1m 50s\tremaining: 1m 9s\n",
      "615:\tlearn: 0.7079661\ttotal: 1m 50s\tremaining: 1m 9s\n",
      "616:\tlearn: 0.7078632\ttotal: 1m 51s\tremaining: 1m 8s\n",
      "617:\tlearn: 0.7077253\ttotal: 1m 51s\tremaining: 1m 8s\n",
      "618:\tlearn: 0.7076459\ttotal: 1m 51s\tremaining: 1m 8s\n",
      "619:\tlearn: 0.7075437\ttotal: 1m 51s\tremaining: 1m 8s\n",
      "620:\tlearn: 0.7074729\ttotal: 1m 51s\tremaining: 1m 8s\n",
      "621:\tlearn: 0.7072014\ttotal: 1m 51s\tremaining: 1m 8s\n",
      "622:\tlearn: 0.7071362\ttotal: 1m 52s\tremaining: 1m 7s\n",
      "623:\tlearn: 0.7069882\ttotal: 1m 52s\tremaining: 1m 7s\n",
      "624:\tlearn: 0.7069331\ttotal: 1m 52s\tremaining: 1m 7s\n",
      "625:\tlearn: 0.7068081\ttotal: 1m 52s\tremaining: 1m 7s\n",
      "626:\tlearn: 0.7066631\ttotal: 1m 52s\tremaining: 1m 7s\n",
      "627:\tlearn: 0.7065816\ttotal: 1m 52s\tremaining: 1m 6s\n",
      "628:\tlearn: 0.7065053\ttotal: 1m 53s\tremaining: 1m 6s\n",
      "629:\tlearn: 0.7064243\ttotal: 1m 53s\tremaining: 1m 6s\n",
      "630:\tlearn: 0.7062949\ttotal: 1m 53s\tremaining: 1m 6s\n",
      "631:\tlearn: 0.7062349\ttotal: 1m 53s\tremaining: 1m 6s\n",
      "632:\tlearn: 0.7061799\ttotal: 1m 53s\tremaining: 1m 5s\n",
      "633:\tlearn: 0.7060822\ttotal: 1m 54s\tremaining: 1m 5s\n",
      "634:\tlearn: 0.7060002\ttotal: 1m 54s\tremaining: 1m 5s\n",
      "635:\tlearn: 0.7059189\ttotal: 1m 54s\tremaining: 1m 5s\n",
      "636:\tlearn: 0.7057628\ttotal: 1m 54s\tremaining: 1m 5s\n",
      "637:\tlearn: 0.7056620\ttotal: 1m 54s\tremaining: 1m 5s\n",
      "638:\tlearn: 0.7055142\ttotal: 1m 54s\tremaining: 1m 4s\n",
      "639:\tlearn: 0.7054452\ttotal: 1m 55s\tremaining: 1m 4s\n",
      "640:\tlearn: 0.7053840\ttotal: 1m 55s\tremaining: 1m 4s\n",
      "641:\tlearn: 0.7051621\ttotal: 1m 55s\tremaining: 1m 4s\n",
      "642:\tlearn: 0.7050156\ttotal: 1m 55s\tremaining: 1m 4s\n",
      "643:\tlearn: 0.7049632\ttotal: 1m 55s\tremaining: 1m 3s\n",
      "644:\tlearn: 0.7048165\ttotal: 1m 55s\tremaining: 1m 3s\n",
      "645:\tlearn: 0.7047625\ttotal: 1m 56s\tremaining: 1m 3s\n",
      "646:\tlearn: 0.7046887\ttotal: 1m 56s\tremaining: 1m 3s\n",
      "647:\tlearn: 0.7045611\ttotal: 1m 56s\tremaining: 1m 3s\n",
      "648:\tlearn: 0.7045040\ttotal: 1m 56s\tremaining: 1m 3s\n",
      "649:\tlearn: 0.7043764\ttotal: 1m 56s\tremaining: 1m 2s\n",
      "650:\tlearn: 0.7042071\ttotal: 1m 56s\tremaining: 1m 2s\n",
      "651:\tlearn: 0.7041607\ttotal: 1m 57s\tremaining: 1m 2s\n",
      "652:\tlearn: 0.7039941\ttotal: 1m 57s\tremaining: 1m 2s\n",
      "653:\tlearn: 0.7037627\ttotal: 1m 57s\tremaining: 1m 2s\n",
      "654:\tlearn: 0.7036659\ttotal: 1m 57s\tremaining: 1m 1s\n",
      "655:\tlearn: 0.7035977\ttotal: 1m 57s\tremaining: 1m 1s\n",
      "656:\tlearn: 0.7034827\ttotal: 1m 57s\tremaining: 1m 1s\n",
      "657:\tlearn: 0.7033745\ttotal: 1m 58s\tremaining: 1m 1s\n",
      "658:\tlearn: 0.7032905\ttotal: 1m 58s\tremaining: 1m 1s\n",
      "659:\tlearn: 0.7031874\ttotal: 1m 58s\tremaining: 1m 1s\n",
      "660:\tlearn: 0.7031152\ttotal: 1m 58s\tremaining: 1m\n",
      "661:\tlearn: 0.7029840\ttotal: 1m 58s\tremaining: 1m\n",
      "662:\tlearn: 0.7027362\ttotal: 1m 59s\tremaining: 1m\n",
      "663:\tlearn: 0.7026355\ttotal: 1m 59s\tremaining: 1m\n",
      "664:\tlearn: 0.7025374\ttotal: 1m 59s\tremaining: 1m\n",
      "665:\tlearn: 0.7024197\ttotal: 1m 59s\tremaining: 59.9s\n",
      "666:\tlearn: 0.7023759\ttotal: 1m 59s\tremaining: 59.8s\n",
      "667:\tlearn: 0.7021961\ttotal: 1m 59s\tremaining: 59.6s\n",
      "668:\tlearn: 0.7021191\ttotal: 2m\tremaining: 59.4s\n",
      "669:\tlearn: 0.7020963\ttotal: 2m\tremaining: 59.2s\n",
      "670:\tlearn: 0.7019445\ttotal: 2m\tremaining: 59s\n",
      "671:\tlearn: 0.7019063\ttotal: 2m\tremaining: 58.9s\n",
      "672:\tlearn: 0.7018104\ttotal: 2m\tremaining: 58.7s\n",
      "673:\tlearn: 0.7016366\ttotal: 2m\tremaining: 58.5s\n",
      "674:\tlearn: 0.7015972\ttotal: 2m 1s\tremaining: 58.3s\n",
      "675:\tlearn: 0.7014739\ttotal: 2m 1s\tremaining: 58.2s\n",
      "676:\tlearn: 0.7013761\ttotal: 2m 1s\tremaining: 58s\n",
      "677:\tlearn: 0.7013002\ttotal: 2m 1s\tremaining: 57.8s\n",
      "678:\tlearn: 0.7011637\ttotal: 2m 1s\tremaining: 57.6s\n",
      "679:\tlearn: 0.7010751\ttotal: 2m 2s\tremaining: 57.4s\n",
      "680:\tlearn: 0.7009409\ttotal: 2m 2s\tremaining: 57.2s\n",
      "681:\tlearn: 0.7008528\ttotal: 2m 2s\tremaining: 57.1s\n",
      "682:\tlearn: 0.7007752\ttotal: 2m 2s\tremaining: 56.9s\n",
      "683:\tlearn: 0.7005768\ttotal: 2m 2s\tremaining: 56.7s\n",
      "684:\tlearn: 0.7004900\ttotal: 2m 2s\tremaining: 56.5s\n",
      "685:\tlearn: 0.7004372\ttotal: 2m 3s\tremaining: 56.3s\n",
      "686:\tlearn: 0.7003883\ttotal: 2m 3s\tremaining: 56.1s\n",
      "687:\tlearn: 0.7003512\ttotal: 2m 3s\tremaining: 55.9s\n",
      "688:\tlearn: 0.7002682\ttotal: 2m 3s\tremaining: 55.8s\n",
      "689:\tlearn: 0.7001785\ttotal: 2m 3s\tremaining: 55.6s\n",
      "690:\tlearn: 0.7001094\ttotal: 2m 3s\tremaining: 55.4s\n",
      "691:\tlearn: 0.7000704\ttotal: 2m 4s\tremaining: 55.2s\n",
      "692:\tlearn: 0.7000397\ttotal: 2m 4s\tremaining: 55s\n",
      "693:\tlearn: 0.6999304\ttotal: 2m 4s\tremaining: 54.9s\n",
      "694:\tlearn: 0.6998933\ttotal: 2m 4s\tremaining: 54.7s\n",
      "695:\tlearn: 0.6997633\ttotal: 2m 4s\tremaining: 54.5s\n",
      "696:\tlearn: 0.6997156\ttotal: 2m 5s\tremaining: 54.3s\n",
      "697:\tlearn: 0.6996383\ttotal: 2m 5s\tremaining: 54.2s\n",
      "698:\tlearn: 0.6995630\ttotal: 2m 5s\tremaining: 54s\n",
      "699:\tlearn: 0.6994590\ttotal: 2m 5s\tremaining: 53.8s\n",
      "700:\tlearn: 0.6992945\ttotal: 2m 5s\tremaining: 53.6s\n",
      "701:\tlearn: 0.6991766\ttotal: 2m 5s\tremaining: 53.5s\n",
      "702:\tlearn: 0.6990962\ttotal: 2m 6s\tremaining: 53.3s\n",
      "703:\tlearn: 0.6989938\ttotal: 2m 6s\tremaining: 53.1s\n",
      "704:\tlearn: 0.6988538\ttotal: 2m 6s\tremaining: 52.9s\n",
      "705:\tlearn: 0.6987516\ttotal: 2m 6s\tremaining: 52.7s\n",
      "706:\tlearn: 0.6986735\ttotal: 2m 6s\tremaining: 52.5s\n",
      "707:\tlearn: 0.6986332\ttotal: 2m 6s\tremaining: 52.4s\n",
      "708:\tlearn: 0.6985796\ttotal: 2m 7s\tremaining: 52.2s\n",
      "709:\tlearn: 0.6983679\ttotal: 2m 7s\tremaining: 52s\n",
      "710:\tlearn: 0.6981990\ttotal: 2m 7s\tremaining: 51.8s\n",
      "711:\tlearn: 0.6981357\ttotal: 2m 7s\tremaining: 51.7s\n",
      "712:\tlearn: 0.6980525\ttotal: 2m 7s\tremaining: 51.5s\n",
      "713:\tlearn: 0.6979555\ttotal: 2m 8s\tremaining: 51.3s\n",
      "714:\tlearn: 0.6979273\ttotal: 2m 8s\tremaining: 51.1s\n",
      "715:\tlearn: 0.6978255\ttotal: 2m 8s\tremaining: 50.9s\n",
      "716:\tlearn: 0.6977786\ttotal: 2m 8s\tremaining: 50.7s\n",
      "717:\tlearn: 0.6976963\ttotal: 2m 8s\tremaining: 50.6s\n",
      "718:\tlearn: 0.6976450\ttotal: 2m 8s\tremaining: 50.4s\n",
      "719:\tlearn: 0.6975929\ttotal: 2m 9s\tremaining: 50.2s\n",
      "720:\tlearn: 0.6975203\ttotal: 2m 9s\tremaining: 50s\n",
      "721:\tlearn: 0.6974445\ttotal: 2m 9s\tremaining: 49.8s\n",
      "722:\tlearn: 0.6973377\ttotal: 2m 9s\tremaining: 49.7s\n",
      "723:\tlearn: 0.6972802\ttotal: 2m 9s\tremaining: 49.5s\n",
      "724:\tlearn: 0.6971824\ttotal: 2m 9s\tremaining: 49.3s\n",
      "725:\tlearn: 0.6971322\ttotal: 2m 10s\tremaining: 49.1s\n",
      "726:\tlearn: 0.6970510\ttotal: 2m 10s\tremaining: 48.9s\n",
      "727:\tlearn: 0.6968873\ttotal: 2m 10s\tremaining: 48.7s\n",
      "728:\tlearn: 0.6968413\ttotal: 2m 10s\tremaining: 48.6s\n",
      "729:\tlearn: 0.6967928\ttotal: 2m 10s\tremaining: 48.4s\n",
      "730:\tlearn: 0.6966245\ttotal: 2m 11s\tremaining: 48.2s\n",
      "731:\tlearn: 0.6965342\ttotal: 2m 11s\tremaining: 48s\n",
      "732:\tlearn: 0.6964853\ttotal: 2m 11s\tremaining: 47.9s\n",
      "733:\tlearn: 0.6963936\ttotal: 2m 11s\tremaining: 47.7s\n",
      "734:\tlearn: 0.6962657\ttotal: 2m 11s\tremaining: 47.5s\n",
      "735:\tlearn: 0.6962078\ttotal: 2m 11s\tremaining: 47.3s\n",
      "736:\tlearn: 0.6961139\ttotal: 2m 12s\tremaining: 47.1s\n",
      "737:\tlearn: 0.6960018\ttotal: 2m 12s\tremaining: 47s\n",
      "738:\tlearn: 0.6959423\ttotal: 2m 12s\tremaining: 46.8s\n",
      "739:\tlearn: 0.6958872\ttotal: 2m 12s\tremaining: 46.6s\n",
      "740:\tlearn: 0.6957935\ttotal: 2m 12s\tremaining: 46.4s\n",
      "741:\tlearn: 0.6957418\ttotal: 2m 12s\tremaining: 46.2s\n",
      "742:\tlearn: 0.6955730\ttotal: 2m 13s\tremaining: 46.1s\n",
      "743:\tlearn: 0.6955172\ttotal: 2m 13s\tremaining: 45.9s\n",
      "744:\tlearn: 0.6954420\ttotal: 2m 13s\tremaining: 45.7s\n",
      "745:\tlearn: 0.6953845\ttotal: 2m 13s\tremaining: 45.5s\n",
      "746:\tlearn: 0.6952997\ttotal: 2m 13s\tremaining: 45.3s\n",
      "747:\tlearn: 0.6951514\ttotal: 2m 13s\tremaining: 45.1s\n",
      "748:\tlearn: 0.6951124\ttotal: 2m 14s\tremaining: 45s\n",
      "749:\tlearn: 0.6950386\ttotal: 2m 14s\tremaining: 44.8s\n",
      "750:\tlearn: 0.6949094\ttotal: 2m 14s\tremaining: 44.6s\n",
      "751:\tlearn: 0.6947348\ttotal: 2m 14s\tremaining: 44.4s\n",
      "752:\tlearn: 0.6946715\ttotal: 2m 14s\tremaining: 44.2s\n",
      "753:\tlearn: 0.6945857\ttotal: 2m 15s\tremaining: 44.1s\n",
      "754:\tlearn: 0.6945177\ttotal: 2m 15s\tremaining: 43.9s\n",
      "755:\tlearn: 0.6944381\ttotal: 2m 15s\tremaining: 43.7s\n",
      "756:\tlearn: 0.6943821\ttotal: 2m 15s\tremaining: 43.5s\n",
      "757:\tlearn: 0.6942659\ttotal: 2m 15s\tremaining: 43.3s\n",
      "758:\tlearn: 0.6941636\ttotal: 2m 15s\tremaining: 43.2s\n",
      "759:\tlearn: 0.6941229\ttotal: 2m 16s\tremaining: 43s\n",
      "760:\tlearn: 0.6940731\ttotal: 2m 16s\tremaining: 42.8s\n",
      "761:\tlearn: 0.6940325\ttotal: 2m 16s\tremaining: 42.6s\n",
      "762:\tlearn: 0.6938747\ttotal: 2m 16s\tremaining: 42.4s\n",
      "763:\tlearn: 0.6937828\ttotal: 2m 16s\tremaining: 42.3s\n",
      "764:\tlearn: 0.6936949\ttotal: 2m 16s\tremaining: 42.1s\n",
      "765:\tlearn: 0.6936627\ttotal: 2m 17s\tremaining: 41.9s\n",
      "766:\tlearn: 0.6936402\ttotal: 2m 17s\tremaining: 41.7s\n",
      "767:\tlearn: 0.6936229\ttotal: 2m 17s\tremaining: 41.5s\n",
      "768:\tlearn: 0.6935207\ttotal: 2m 17s\tremaining: 41.4s\n",
      "769:\tlearn: 0.6934347\ttotal: 2m 17s\tremaining: 41.2s\n",
      "770:\tlearn: 0.6933817\ttotal: 2m 18s\tremaining: 41s\n",
      "771:\tlearn: 0.6933437\ttotal: 2m 18s\tremaining: 40.8s\n",
      "772:\tlearn: 0.6932511\ttotal: 2m 18s\tremaining: 40.6s\n",
      "773:\tlearn: 0.6931854\ttotal: 2m 18s\tremaining: 40.5s\n",
      "774:\tlearn: 0.6931207\ttotal: 2m 18s\tremaining: 40.3s\n",
      "775:\tlearn: 0.6929520\ttotal: 2m 18s\tremaining: 40.1s\n",
      "776:\tlearn: 0.6928524\ttotal: 2m 19s\tremaining: 39.9s\n",
      "777:\tlearn: 0.6927448\ttotal: 2m 19s\tremaining: 39.8s\n",
      "778:\tlearn: 0.6926180\ttotal: 2m 19s\tremaining: 39.6s\n",
      "779:\tlearn: 0.6925043\ttotal: 2m 19s\tremaining: 39.4s\n",
      "780:\tlearn: 0.6924523\ttotal: 2m 19s\tremaining: 39.2s\n",
      "781:\tlearn: 0.6924177\ttotal: 2m 20s\tremaining: 39s\n",
      "782:\tlearn: 0.6922917\ttotal: 2m 20s\tremaining: 38.9s\n",
      "783:\tlearn: 0.6922068\ttotal: 2m 20s\tremaining: 38.7s\n",
      "784:\tlearn: 0.6921631\ttotal: 2m 20s\tremaining: 38.5s\n",
      "785:\tlearn: 0.6920472\ttotal: 2m 20s\tremaining: 38.3s\n",
      "786:\tlearn: 0.6919737\ttotal: 2m 20s\tremaining: 38.1s\n",
      "787:\tlearn: 0.6918729\ttotal: 2m 21s\tremaining: 38s\n",
      "788:\tlearn: 0.6918089\ttotal: 2m 21s\tremaining: 37.8s\n",
      "789:\tlearn: 0.6917354\ttotal: 2m 21s\tremaining: 37.6s\n",
      "790:\tlearn: 0.6916675\ttotal: 2m 21s\tremaining: 37.4s\n",
      "791:\tlearn: 0.6916018\ttotal: 2m 21s\tremaining: 37.2s\n",
      "792:\tlearn: 0.6915497\ttotal: 2m 21s\tremaining: 37.1s\n",
      "793:\tlearn: 0.6914912\ttotal: 2m 22s\tremaining: 36.9s\n",
      "794:\tlearn: 0.6914398\ttotal: 2m 22s\tremaining: 36.7s\n",
      "795:\tlearn: 0.6914209\ttotal: 2m 22s\tremaining: 36.5s\n",
      "796:\tlearn: 0.6912744\ttotal: 2m 22s\tremaining: 36.3s\n",
      "797:\tlearn: 0.6912077\ttotal: 2m 22s\tremaining: 36.2s\n",
      "798:\tlearn: 0.6911075\ttotal: 2m 22s\tremaining: 36s\n",
      "799:\tlearn: 0.6909958\ttotal: 2m 23s\tremaining: 35.8s\n",
      "800:\tlearn: 0.6908700\ttotal: 2m 23s\tremaining: 35.6s\n",
      "801:\tlearn: 0.6907590\ttotal: 2m 23s\tremaining: 35.4s\n",
      "802:\tlearn: 0.6906166\ttotal: 2m 23s\tremaining: 35.2s\n",
      "803:\tlearn: 0.6905734\ttotal: 2m 23s\tremaining: 35.1s\n",
      "804:\tlearn: 0.6905189\ttotal: 2m 24s\tremaining: 34.9s\n",
      "805:\tlearn: 0.6904241\ttotal: 2m 24s\tremaining: 34.7s\n",
      "806:\tlearn: 0.6903553\ttotal: 2m 24s\tremaining: 34.5s\n",
      "807:\tlearn: 0.6901730\ttotal: 2m 24s\tremaining: 34.3s\n",
      "808:\tlearn: 0.6901099\ttotal: 2m 24s\tremaining: 34.2s\n",
      "809:\tlearn: 0.6900213\ttotal: 2m 24s\tremaining: 34s\n",
      "810:\tlearn: 0.6898903\ttotal: 2m 25s\tremaining: 33.8s\n",
      "811:\tlearn: 0.6898033\ttotal: 2m 25s\tremaining: 33.6s\n",
      "812:\tlearn: 0.6897419\ttotal: 2m 25s\tremaining: 33.4s\n",
      "813:\tlearn: 0.6896396\ttotal: 2m 25s\tremaining: 33.2s\n",
      "814:\tlearn: 0.6895766\ttotal: 2m 25s\tremaining: 33.1s\n",
      "815:\tlearn: 0.6895153\ttotal: 2m 25s\tremaining: 32.9s\n",
      "816:\tlearn: 0.6894365\ttotal: 2m 26s\tremaining: 32.7s\n",
      "817:\tlearn: 0.6892691\ttotal: 2m 26s\tremaining: 32.5s\n",
      "818:\tlearn: 0.6892053\ttotal: 2m 26s\tremaining: 32.3s\n",
      "819:\tlearn: 0.6891664\ttotal: 2m 26s\tremaining: 32.2s\n",
      "820:\tlearn: 0.6890757\ttotal: 2m 26s\tremaining: 32s\n",
      "821:\tlearn: 0.6890073\ttotal: 2m 26s\tremaining: 31.8s\n",
      "822:\tlearn: 0.6889563\ttotal: 2m 27s\tremaining: 31.6s\n",
      "823:\tlearn: 0.6889011\ttotal: 2m 27s\tremaining: 31.4s\n",
      "824:\tlearn: 0.6887487\ttotal: 2m 27s\tremaining: 31.3s\n",
      "825:\tlearn: 0.6886710\ttotal: 2m 27s\tremaining: 31.1s\n",
      "826:\tlearn: 0.6886145\ttotal: 2m 27s\tremaining: 30.9s\n",
      "827:\tlearn: 0.6885164\ttotal: 2m 27s\tremaining: 30.7s\n",
      "828:\tlearn: 0.6884078\ttotal: 2m 28s\tremaining: 30.5s\n",
      "829:\tlearn: 0.6882339\ttotal: 2m 28s\tremaining: 30.4s\n",
      "830:\tlearn: 0.6880953\ttotal: 2m 28s\tremaining: 30.2s\n",
      "831:\tlearn: 0.6880582\ttotal: 2m 28s\tremaining: 30s\n",
      "832:\tlearn: 0.6880322\ttotal: 2m 28s\tremaining: 29.8s\n",
      "833:\tlearn: 0.6879738\ttotal: 2m 28s\tremaining: 29.6s\n",
      "834:\tlearn: 0.6879106\ttotal: 2m 29s\tremaining: 29.5s\n",
      "835:\tlearn: 0.6878850\ttotal: 2m 29s\tremaining: 29.3s\n",
      "836:\tlearn: 0.6878321\ttotal: 2m 29s\tremaining: 29.1s\n",
      "837:\tlearn: 0.6877482\ttotal: 2m 29s\tremaining: 28.9s\n",
      "838:\tlearn: 0.6876718\ttotal: 2m 29s\tremaining: 28.7s\n",
      "839:\tlearn: 0.6876060\ttotal: 2m 29s\tremaining: 28.6s\n",
      "840:\tlearn: 0.6874909\ttotal: 2m 30s\tremaining: 28.4s\n",
      "841:\tlearn: 0.6874442\ttotal: 2m 30s\tremaining: 28.2s\n",
      "842:\tlearn: 0.6874149\ttotal: 2m 30s\tremaining: 28s\n",
      "843:\tlearn: 0.6873329\ttotal: 2m 30s\tremaining: 27.8s\n",
      "844:\tlearn: 0.6871783\ttotal: 2m 30s\tremaining: 27.7s\n",
      "845:\tlearn: 0.6871171\ttotal: 2m 30s\tremaining: 27.5s\n",
      "846:\tlearn: 0.6870697\ttotal: 2m 31s\tremaining: 27.3s\n",
      "847:\tlearn: 0.6869927\ttotal: 2m 31s\tremaining: 27.1s\n",
      "848:\tlearn: 0.6868802\ttotal: 2m 31s\tremaining: 26.9s\n",
      "849:\tlearn: 0.6868315\ttotal: 2m 31s\tremaining: 26.8s\n",
      "850:\tlearn: 0.6867684\ttotal: 2m 31s\tremaining: 26.6s\n",
      "851:\tlearn: 0.6867475\ttotal: 2m 31s\tremaining: 26.4s\n",
      "852:\tlearn: 0.6866158\ttotal: 2m 32s\tremaining: 26.2s\n",
      "853:\tlearn: 0.6864961\ttotal: 2m 32s\tremaining: 26s\n",
      "854:\tlearn: 0.6863681\ttotal: 2m 32s\tremaining: 25.9s\n",
      "855:\tlearn: 0.6863095\ttotal: 2m 32s\tremaining: 25.7s\n",
      "856:\tlearn: 0.6862544\ttotal: 2m 32s\tremaining: 25.5s\n",
      "857:\tlearn: 0.6862082\ttotal: 2m 33s\tremaining: 25.3s\n",
      "858:\tlearn: 0.6861396\ttotal: 2m 33s\tremaining: 25.1s\n",
      "859:\tlearn: 0.6859966\ttotal: 2m 33s\tremaining: 25s\n",
      "860:\tlearn: 0.6859574\ttotal: 2m 33s\tremaining: 24.8s\n",
      "861:\tlearn: 0.6858589\ttotal: 2m 33s\tremaining: 24.6s\n",
      "862:\tlearn: 0.6857120\ttotal: 2m 33s\tremaining: 24.4s\n",
      "863:\tlearn: 0.6856774\ttotal: 2m 34s\tremaining: 24.2s\n",
      "864:\tlearn: 0.6854936\ttotal: 2m 34s\tremaining: 24.1s\n",
      "865:\tlearn: 0.6853970\ttotal: 2m 34s\tremaining: 23.9s\n",
      "866:\tlearn: 0.6853796\ttotal: 2m 34s\tremaining: 23.7s\n",
      "867:\tlearn: 0.6853408\ttotal: 2m 34s\tremaining: 23.5s\n",
      "868:\tlearn: 0.6852598\ttotal: 2m 35s\tremaining: 23.4s\n",
      "869:\tlearn: 0.6852157\ttotal: 2m 35s\tremaining: 23.2s\n",
      "870:\tlearn: 0.6851517\ttotal: 2m 35s\tremaining: 23s\n",
      "871:\tlearn: 0.6850602\ttotal: 2m 35s\tremaining: 22.8s\n",
      "872:\tlearn: 0.6850001\ttotal: 2m 35s\tremaining: 22.7s\n",
      "873:\tlearn: 0.6848826\ttotal: 2m 35s\tremaining: 22.5s\n",
      "874:\tlearn: 0.6848203\ttotal: 2m 36s\tremaining: 22.3s\n",
      "875:\tlearn: 0.6847475\ttotal: 2m 36s\tremaining: 22.1s\n",
      "876:\tlearn: 0.6847021\ttotal: 2m 36s\tremaining: 21.9s\n",
      "877:\tlearn: 0.6845841\ttotal: 2m 36s\tremaining: 21.8s\n",
      "878:\tlearn: 0.6845357\ttotal: 2m 36s\tremaining: 21.6s\n",
      "879:\tlearn: 0.6845032\ttotal: 2m 36s\tremaining: 21.4s\n",
      "880:\tlearn: 0.6844361\ttotal: 2m 37s\tremaining: 21.2s\n",
      "881:\tlearn: 0.6842804\ttotal: 2m 37s\tremaining: 21s\n",
      "882:\tlearn: 0.6841574\ttotal: 2m 37s\tremaining: 20.9s\n",
      "883:\tlearn: 0.6841405\ttotal: 2m 37s\tremaining: 20.7s\n",
      "884:\tlearn: 0.6841255\ttotal: 2m 37s\tremaining: 20.5s\n",
      "885:\tlearn: 0.6839883\ttotal: 2m 37s\tremaining: 20.3s\n",
      "886:\tlearn: 0.6839044\ttotal: 2m 38s\tremaining: 20.1s\n",
      "887:\tlearn: 0.6838617\ttotal: 2m 38s\tremaining: 20s\n",
      "888:\tlearn: 0.6838352\ttotal: 2m 38s\tremaining: 19.8s\n",
      "889:\tlearn: 0.6837282\ttotal: 2m 38s\tremaining: 19.6s\n",
      "890:\tlearn: 0.6836989\ttotal: 2m 38s\tremaining: 19.4s\n",
      "891:\tlearn: 0.6836762\ttotal: 2m 39s\tremaining: 19.3s\n",
      "892:\tlearn: 0.6836016\ttotal: 2m 39s\tremaining: 19.1s\n",
      "893:\tlearn: 0.6835319\ttotal: 2m 39s\tremaining: 18.9s\n",
      "894:\tlearn: 0.6835126\ttotal: 2m 39s\tremaining: 18.7s\n",
      "895:\tlearn: 0.6834021\ttotal: 2m 39s\tremaining: 18.5s\n",
      "896:\tlearn: 0.6833814\ttotal: 2m 39s\tremaining: 18.4s\n",
      "897:\tlearn: 0.6832800\ttotal: 2m 40s\tremaining: 18.2s\n",
      "898:\tlearn: 0.6832162\ttotal: 2m 40s\tremaining: 18s\n",
      "899:\tlearn: 0.6831779\ttotal: 2m 40s\tremaining: 17.8s\n",
      "900:\tlearn: 0.6831222\ttotal: 2m 40s\tremaining: 17.6s\n",
      "901:\tlearn: 0.6829668\ttotal: 2m 40s\tremaining: 17.5s\n",
      "902:\tlearn: 0.6828928\ttotal: 2m 40s\tremaining: 17.3s\n",
      "903:\tlearn: 0.6828023\ttotal: 2m 41s\tremaining: 17.1s\n",
      "904:\tlearn: 0.6827483\ttotal: 2m 41s\tremaining: 16.9s\n",
      "905:\tlearn: 0.6826855\ttotal: 2m 41s\tremaining: 16.8s\n",
      "906:\tlearn: 0.6826526\ttotal: 2m 41s\tremaining: 16.6s\n",
      "907:\tlearn: 0.6826018\ttotal: 2m 41s\tremaining: 16.4s\n",
      "908:\tlearn: 0.6825422\ttotal: 2m 41s\tremaining: 16.2s\n",
      "909:\tlearn: 0.6824793\ttotal: 2m 42s\tremaining: 16s\n",
      "910:\tlearn: 0.6823777\ttotal: 2m 42s\tremaining: 15.9s\n",
      "911:\tlearn: 0.6823267\ttotal: 2m 42s\tremaining: 15.7s\n",
      "912:\tlearn: 0.6822552\ttotal: 2m 42s\tremaining: 15.5s\n",
      "913:\tlearn: 0.6821855\ttotal: 2m 42s\tremaining: 15.3s\n",
      "914:\tlearn: 0.6819796\ttotal: 2m 43s\tremaining: 15.1s\n",
      "915:\tlearn: 0.6819495\ttotal: 2m 43s\tremaining: 15s\n",
      "916:\tlearn: 0.6818770\ttotal: 2m 43s\tremaining: 14.8s\n",
      "917:\tlearn: 0.6818242\ttotal: 2m 43s\tremaining: 14.6s\n",
      "918:\tlearn: 0.6817574\ttotal: 2m 43s\tremaining: 14.4s\n",
      "919:\tlearn: 0.6817144\ttotal: 2m 43s\tremaining: 14.3s\n",
      "920:\tlearn: 0.6816534\ttotal: 2m 44s\tremaining: 14.1s\n",
      "921:\tlearn: 0.6815975\ttotal: 2m 44s\tremaining: 13.9s\n",
      "922:\tlearn: 0.6815440\ttotal: 2m 44s\tremaining: 13.7s\n",
      "923:\tlearn: 0.6814457\ttotal: 2m 44s\tremaining: 13.5s\n",
      "924:\tlearn: 0.6813523\ttotal: 2m 44s\tremaining: 13.4s\n",
      "925:\tlearn: 0.6813319\ttotal: 2m 44s\tremaining: 13.2s\n",
      "926:\tlearn: 0.6813075\ttotal: 2m 45s\tremaining: 13s\n",
      "927:\tlearn: 0.6812907\ttotal: 2m 45s\tremaining: 12.8s\n",
      "928:\tlearn: 0.6812705\ttotal: 2m 45s\tremaining: 12.6s\n",
      "929:\tlearn: 0.6811888\ttotal: 2m 45s\tremaining: 12.5s\n",
      "930:\tlearn: 0.6811103\ttotal: 2m 45s\tremaining: 12.3s\n",
      "931:\tlearn: 0.6810395\ttotal: 2m 45s\tremaining: 12.1s\n",
      "932:\tlearn: 0.6809931\ttotal: 2m 46s\tremaining: 11.9s\n",
      "933:\tlearn: 0.6809220\ttotal: 2m 46s\tremaining: 11.8s\n",
      "934:\tlearn: 0.6808059\ttotal: 2m 46s\tremaining: 11.6s\n",
      "935:\tlearn: 0.6807752\ttotal: 2m 46s\tremaining: 11.4s\n",
      "936:\tlearn: 0.6807291\ttotal: 2m 46s\tremaining: 11.2s\n",
      "937:\tlearn: 0.6807036\ttotal: 2m 47s\tremaining: 11s\n",
      "938:\tlearn: 0.6806665\ttotal: 2m 47s\tremaining: 10.9s\n",
      "939:\tlearn: 0.6806088\ttotal: 2m 47s\tremaining: 10.7s\n",
      "940:\tlearn: 0.6805863\ttotal: 2m 47s\tremaining: 10.5s\n",
      "941:\tlearn: 0.6805050\ttotal: 2m 47s\tremaining: 10.3s\n",
      "942:\tlearn: 0.6804380\ttotal: 2m 47s\tremaining: 10.2s\n",
      "943:\tlearn: 0.6804130\ttotal: 2m 48s\tremaining: 9.97s\n",
      "944:\tlearn: 0.6803645\ttotal: 2m 48s\tremaining: 9.8s\n",
      "945:\tlearn: 0.6803074\ttotal: 2m 48s\tremaining: 9.62s\n",
      "946:\tlearn: 0.6800712\ttotal: 2m 48s\tremaining: 9.44s\n",
      "947:\tlearn: 0.6800198\ttotal: 2m 48s\tremaining: 9.27s\n",
      "948:\tlearn: 0.6799848\ttotal: 2m 49s\tremaining: 9.09s\n",
      "949:\tlearn: 0.6799264\ttotal: 2m 49s\tremaining: 8.91s\n",
      "950:\tlearn: 0.6798949\ttotal: 2m 49s\tremaining: 8.73s\n",
      "951:\tlearn: 0.6798483\ttotal: 2m 49s\tremaining: 8.55s\n",
      "952:\tlearn: 0.6797744\ttotal: 2m 49s\tremaining: 8.38s\n",
      "953:\tlearn: 0.6797446\ttotal: 2m 50s\tremaining: 8.2s\n",
      "954:\tlearn: 0.6797004\ttotal: 2m 50s\tremaining: 8.02s\n",
      "955:\tlearn: 0.6796311\ttotal: 2m 50s\tremaining: 7.84s\n",
      "956:\tlearn: 0.6794937\ttotal: 2m 50s\tremaining: 7.66s\n",
      "957:\tlearn: 0.6794143\ttotal: 2m 50s\tremaining: 7.49s\n",
      "958:\tlearn: 0.6793870\ttotal: 2m 50s\tremaining: 7.31s\n",
      "959:\tlearn: 0.6793185\ttotal: 2m 51s\tremaining: 7.13s\n",
      "960:\tlearn: 0.6792799\ttotal: 2m 51s\tremaining: 6.95s\n",
      "961:\tlearn: 0.6791662\ttotal: 2m 51s\tremaining: 6.77s\n",
      "962:\tlearn: 0.6791189\ttotal: 2m 51s\tremaining: 6.59s\n",
      "963:\tlearn: 0.6790498\ttotal: 2m 51s\tremaining: 6.42s\n",
      "964:\tlearn: 0.6789271\ttotal: 2m 51s\tremaining: 6.24s\n",
      "965:\tlearn: 0.6788532\ttotal: 2m 52s\tremaining: 6.06s\n",
      "966:\tlearn: 0.6788129\ttotal: 2m 52s\tremaining: 5.88s\n",
      "967:\tlearn: 0.6787342\ttotal: 2m 52s\tremaining: 5.7s\n",
      "968:\tlearn: 0.6786277\ttotal: 2m 52s\tremaining: 5.52s\n",
      "969:\tlearn: 0.6785940\ttotal: 2m 52s\tremaining: 5.34s\n",
      "970:\tlearn: 0.6785672\ttotal: 2m 53s\tremaining: 5.17s\n",
      "971:\tlearn: 0.6785060\ttotal: 2m 53s\tremaining: 4.99s\n",
      "972:\tlearn: 0.6784080\ttotal: 2m 53s\tremaining: 4.81s\n",
      "973:\tlearn: 0.6783797\ttotal: 2m 53s\tremaining: 4.63s\n",
      "974:\tlearn: 0.6783222\ttotal: 2m 53s\tremaining: 4.46s\n",
      "975:\tlearn: 0.6781219\ttotal: 2m 53s\tremaining: 4.28s\n",
      "976:\tlearn: 0.6780712\ttotal: 2m 54s\tremaining: 4.1s\n",
      "977:\tlearn: 0.6779301\ttotal: 2m 54s\tremaining: 3.92s\n",
      "978:\tlearn: 0.6778224\ttotal: 2m 54s\tremaining: 3.74s\n",
      "979:\tlearn: 0.6777927\ttotal: 2m 54s\tremaining: 3.56s\n",
      "980:\tlearn: 0.6777380\ttotal: 2m 54s\tremaining: 3.39s\n",
      "981:\tlearn: 0.6776732\ttotal: 2m 55s\tremaining: 3.21s\n",
      "982:\tlearn: 0.6776248\ttotal: 2m 55s\tremaining: 3.03s\n",
      "983:\tlearn: 0.6775152\ttotal: 2m 55s\tremaining: 2.85s\n",
      "984:\tlearn: 0.6774590\ttotal: 2m 55s\tremaining: 2.67s\n",
      "985:\tlearn: 0.6774037\ttotal: 2m 55s\tremaining: 2.5s\n",
      "986:\tlearn: 0.6772566\ttotal: 2m 55s\tremaining: 2.32s\n",
      "987:\tlearn: 0.6772347\ttotal: 2m 56s\tremaining: 2.14s\n",
      "988:\tlearn: 0.6771969\ttotal: 2m 56s\tremaining: 1.96s\n",
      "989:\tlearn: 0.6771672\ttotal: 2m 56s\tremaining: 1.78s\n",
      "990:\tlearn: 0.6771321\ttotal: 2m 56s\tremaining: 1.6s\n",
      "991:\tlearn: 0.6770674\ttotal: 2m 56s\tremaining: 1.43s\n",
      "992:\tlearn: 0.6769871\ttotal: 2m 57s\tremaining: 1.25s\n",
      "993:\tlearn: 0.6769472\ttotal: 2m 57s\tremaining: 1.07s\n",
      "994:\tlearn: 0.6768946\ttotal: 2m 57s\tremaining: 891ms\n",
      "995:\tlearn: 0.6768447\ttotal: 2m 57s\tremaining: 713ms\n",
      "996:\tlearn: 0.6767759\ttotal: 2m 57s\tremaining: 535ms\n",
      "997:\tlearn: 0.6766691\ttotal: 2m 57s\tremaining: 356ms\n",
      "998:\tlearn: 0.6766317\ttotal: 2m 58s\tremaining: 178ms\n",
      "999:\tlearn: 0.6765880\ttotal: 2m 58s\tremaining: 0us\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7553    0.5596    0.6429      2334\n",
      "           1     0.6179    0.7961    0.6958      3335\n",
      "           2     0.8012    0.6901    0.7415      2575\n",
      "\n",
      "    accuracy                         0.6960      8244\n",
      "   macro avg     0.7248    0.6819    0.6934      8244\n",
      "weighted avg     0.7140    0.6960    0.6951      8244\n",
      "\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "models = [LogisticRegression(), MultinomialNB(), SVC(), RandomForestClassifier(), XGBClassifier(), LGBMClassifier(), CatBoostClassifier()]\n",
    "model_names = [\"Logistic Regression\", \"Naive Bayes\", \"SVC\", \"Random Forest\", \"XGBoost\", \"LightGBM\", \"CatBoost\"]\n",
    "for model, name in zip(models, model_names):\n",
    "    print(name)\n",
    "    model.fit(x_train_transformed, y_train)\n",
    "    pred = model.predict(x_valid_transformed)\n",
    "    print(classification_report(y_valid, pred, digits=4))\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_valid = to_categorical(y_valid, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, x_valid, y_train, y_valid):\n",
    "    input_ts = Input(shape=(x_train.shape[1],))\n",
    "    layer_1 = Dense(256, kernel_regularizer = tf.keras.regularizers.l2(0.01), activation = \"relu\")(input_ts)\n",
    "    dropout_1 = Dropout(0.2)(layer_1)\n",
    "    layer_2 = Dense(128, activation = \"relu\")(dropout_1)\n",
    "    layer_3 = Dense(64, activation = \"relu\")(layer_2)\n",
    "    prediction = Dense(3, activation = \"softmax\")(layer_3)\n",
    "    model = Model(inputs=input_ts, outputs=prediction)\n",
    "    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-4 * math.exp(-0.1 * x))\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                    optimizer=tf.optimizers.Adam(),\n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(x_train, y_train,                   \n",
    "                          epochs=100,\n",
    "                          validation_data=(x_valid, y_valid),\n",
    "                          batch_size=64,\n",
    "                          verbose=1,\n",
    "                          callbacks=[lr_scheduler, early_stopping])\n",
    "\n",
    "    # Save the trained model\n",
    "    model.save('model.keras')\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def train_lstm(x_train, x_valid, y_train, y_valid):\n",
    "    input_ts = Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "    lstm_1 = LSTM(128, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.01))(input_ts)\n",
    "    dropout_1 = Dropout(0.5)(lstm_1)\n",
    "\n",
    "    x, *state = RNN(LSTMCell(64), return_state=True)(dropout_1)\n",
    "\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    prediction = Dense(3, activation=\"softmax\")(x)\n",
    "    lstm = Model(inputs=input_ts, outputs=prediction)\n",
    "    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-4 * math.exp(-0.1 * x))\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    lstm.compile(loss=\"categorical_crossentropy\",\n",
    "                    optimizer=tf.optimizers.Adam(),\n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "    history = lstm.fit(x_train, y_train,\n",
    "                          epochs=100,\n",
    "                          validation_data=(x_valid, y_valid),\n",
    "                          batch_size=64,\n",
    "                          verbose=1,\n",
    "                          callbacks=[lr_scheduler, early_stopping])\n",
    "\n",
    "    # Save the trained model\n",
    "    lstm.save('lstm.keras')\n",
    "\n",
    "    return lstm, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.3968 - loss: 3.1114 - val_accuracy: 0.5370 - val_loss: 0.9914 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 71ms/step - accuracy: 0.6027 - loss: 0.9208 - val_accuracy: 0.6813 - val_loss: 0.8243 - learning_rate: 9.0484e-05\n",
      "Epoch 3/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 70ms/step - accuracy: 0.7392 - loss: 0.7521 - val_accuracy: 0.6969 - val_loss: 0.8064 - learning_rate: 8.1873e-05\n",
      "Epoch 4/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 69ms/step - accuracy: 0.7925 - loss: 0.6718 - val_accuracy: 0.6997 - val_loss: 0.8129 - learning_rate: 7.4082e-05\n",
      "Epoch 5/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 69ms/step - accuracy: 0.8258 - loss: 0.6197 - val_accuracy: 0.6923 - val_loss: 0.8268 - learning_rate: 6.7032e-05\n",
      "Epoch 6/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 70ms/step - accuracy: 0.8521 - loss: 0.5717 - val_accuracy: 0.6925 - val_loss: 0.8412 - learning_rate: 6.0653e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 68ms/step - accuracy: 0.8770 - loss: 0.5288 - val_accuracy: 0.6909 - val_loss: 0.8604 - learning_rate: 5.4881e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 68ms/step - accuracy: 0.8916 - loss: 0.4935 - val_accuracy: 0.6927 - val_loss: 0.8695 - learning_rate: 4.9659e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 69ms/step - accuracy: 0.9071 - loss: 0.4588 - val_accuracy: 0.6937 - val_loss: 0.8837 - learning_rate: 4.4933e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 67ms/step - accuracy: 0.9181 - loss: 0.4278 - val_accuracy: 0.6932 - val_loss: 0.8997 - learning_rate: 4.0657e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 67ms/step - accuracy: 0.9256 - loss: 0.4106 - val_accuracy: 0.6890 - val_loss: 0.9138 - learning_rate: 3.6788e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 68ms/step - accuracy: 0.9348 - loss: 0.3800 - val_accuracy: 0.6913 - val_loss: 0.9233 - learning_rate: 3.3287e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 72ms/step - accuracy: 0.9427 - loss: 0.3547 - val_accuracy: 0.6908 - val_loss: 0.9381 - learning_rate: 3.0119e-05\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(x_train_transformed, x_valid_transformed, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 150ms/step - accuracy: 0.3992 - loss: 5.0547 - val_accuracy: 0.4045 - val_loss: 1.0909 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.4122 - loss: 1.0865 - val_accuracy: 0.4045 - val_loss: 1.0871 - learning_rate: 9.0484e-05\n",
      "Epoch 3/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 145ms/step - accuracy: 0.4086 - loss: 1.0861 - val_accuracy: 0.4045 - val_loss: 1.0870 - learning_rate: 8.1873e-05\n",
      "Epoch 4/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 145ms/step - accuracy: 0.4022 - loss: 1.0879 - val_accuracy: 0.4045 - val_loss: 1.0870 - learning_rate: 7.4082e-05\n",
      "Epoch 5/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 145ms/step - accuracy: 0.4051 - loss: 1.0861 - val_accuracy: 0.4045 - val_loss: 1.0867 - learning_rate: 6.7032e-05\n",
      "Epoch 6/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.4055 - loss: 1.0859 - val_accuracy: 0.4045 - val_loss: 1.0862 - learning_rate: 6.0653e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 152ms/step - accuracy: 0.4079 - loss: 1.0846 - val_accuracy: 0.4045 - val_loss: 1.0850 - learning_rate: 5.4881e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 151ms/step - accuracy: 0.4045 - loss: 1.0840 - val_accuracy: 0.4072 - val_loss: 1.0830 - learning_rate: 4.9659e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.4075 - loss: 1.0821 - val_accuracy: 0.4173 - val_loss: 1.0795 - learning_rate: 4.4933e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 148ms/step - accuracy: 0.4148 - loss: 1.0788 - val_accuracy: 0.4374 - val_loss: 1.0744 - learning_rate: 4.0657e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.4415 - loss: 1.0697 - val_accuracy: 0.4635 - val_loss: 1.0681 - learning_rate: 3.6788e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.4623 - loss: 1.0624 - val_accuracy: 0.4790 - val_loss: 1.0600 - learning_rate: 3.3287e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 149ms/step - accuracy: 0.4936 - loss: 1.0491 - val_accuracy: 0.4975 - val_loss: 1.0520 - learning_rate: 3.0119e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.5068 - loss: 1.0417 - val_accuracy: 0.5081 - val_loss: 1.0443 - learning_rate: 2.7253e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5200 - loss: 1.0293 - val_accuracy: 0.5152 - val_loss: 1.0369 - learning_rate: 2.4660e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5374 - loss: 1.0174 - val_accuracy: 0.5230 - val_loss: 1.0301 - learning_rate: 2.2313e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 149ms/step - accuracy: 0.5409 - loss: 1.0081 - val_accuracy: 0.5285 - val_loss: 1.0238 - learning_rate: 2.0190e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5518 - loss: 0.9977 - val_accuracy: 0.5314 - val_loss: 1.0183 - learning_rate: 1.8268e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5496 - loss: 0.9935 - val_accuracy: 0.5351 - val_loss: 1.0134 - learning_rate: 1.6530e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5624 - loss: 0.9799 - val_accuracy: 0.5377 - val_loss: 1.0091 - learning_rate: 1.4957e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.5689 - loss: 0.9723 - val_accuracy: 0.5405 - val_loss: 1.0053 - learning_rate: 1.3534e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5716 - loss: 0.9668 - val_accuracy: 0.5417 - val_loss: 1.0019 - learning_rate: 1.2246e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5687 - loss: 0.9615 - val_accuracy: 0.5415 - val_loss: 0.9990 - learning_rate: 1.1080e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5776 - loss: 0.9554 - val_accuracy: 0.5420 - val_loss: 0.9964 - learning_rate: 1.0026e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5782 - loss: 0.9514 - val_accuracy: 0.5440 - val_loss: 0.9941 - learning_rate: 9.0718e-06\n",
      "Epoch 26/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5787 - loss: 0.9477 - val_accuracy: 0.5452 - val_loss: 0.9921 - learning_rate: 8.2085e-06\n",
      "Epoch 27/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5788 - loss: 0.9444 - val_accuracy: 0.5462 - val_loss: 0.9903 - learning_rate: 7.4274e-06\n",
      "Epoch 28/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5867 - loss: 0.9364 - val_accuracy: 0.5472 - val_loss: 0.9887 - learning_rate: 6.7206e-06\n",
      "Epoch 29/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.5768 - loss: 0.9393 - val_accuracy: 0.5463 - val_loss: 0.9873 - learning_rate: 6.0810e-06\n",
      "Epoch 30/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.5790 - loss: 0.9351 - val_accuracy: 0.5473 - val_loss: 0.9861 - learning_rate: 5.5023e-06\n",
      "Epoch 31/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5867 - loss: 0.9318 - val_accuracy: 0.5478 - val_loss: 0.9850 - learning_rate: 4.9787e-06\n",
      "Epoch 32/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5919 - loss: 0.9270 - val_accuracy: 0.5477 - val_loss: 0.9840 - learning_rate: 4.5049e-06\n",
      "Epoch 33/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5873 - loss: 0.9289 - val_accuracy: 0.5478 - val_loss: 0.9831 - learning_rate: 4.0762e-06\n",
      "Epoch 34/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5882 - loss: 0.9255 - val_accuracy: 0.5482 - val_loss: 0.9823 - learning_rate: 3.6883e-06\n",
      "Epoch 35/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5861 - loss: 0.9237 - val_accuracy: 0.5486 - val_loss: 0.9816 - learning_rate: 3.3373e-06\n",
      "Epoch 36/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5891 - loss: 0.9230 - val_accuracy: 0.5489 - val_loss: 0.9810 - learning_rate: 3.0197e-06\n",
      "Epoch 37/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5884 - loss: 0.9184 - val_accuracy: 0.5494 - val_loss: 0.9804 - learning_rate: 2.7324e-06\n",
      "Epoch 38/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5903 - loss: 0.9189 - val_accuracy: 0.5495 - val_loss: 0.9799 - learning_rate: 2.4724e-06\n",
      "Epoch 39/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5875 - loss: 0.9197 - val_accuracy: 0.5499 - val_loss: 0.9795 - learning_rate: 2.2371e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5942 - loss: 0.9156 - val_accuracy: 0.5497 - val_loss: 0.9791 - learning_rate: 2.0242e-06\n",
      "Epoch 41/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.5883 - loss: 0.9181 - val_accuracy: 0.5495 - val_loss: 0.9787 - learning_rate: 1.8316e-06\n",
      "Epoch 42/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5943 - loss: 0.9124 - val_accuracy: 0.5496 - val_loss: 0.9784 - learning_rate: 1.6573e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5874 - loss: 0.9165 - val_accuracy: 0.5497 - val_loss: 0.9781 - learning_rate: 1.4996e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.5895 - loss: 0.9144 - val_accuracy: 0.5499 - val_loss: 0.9779 - learning_rate: 1.3569e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.5895 - loss: 0.9132 - val_accuracy: 0.5500 - val_loss: 0.9776 - learning_rate: 1.2277e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5958 - loss: 0.9101 - val_accuracy: 0.5503 - val_loss: 0.9774 - learning_rate: 1.1109e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5878 - loss: 0.9169 - val_accuracy: 0.5503 - val_loss: 0.9772 - learning_rate: 1.0052e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5873 - loss: 0.9142 - val_accuracy: 0.5506 - val_loss: 0.9770 - learning_rate: 9.0953e-07\n",
      "Epoch 49/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5872 - loss: 0.9146 - val_accuracy: 0.5506 - val_loss: 0.9769 - learning_rate: 8.2297e-07\n",
      "Epoch 50/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5921 - loss: 0.9111 - val_accuracy: 0.5506 - val_loss: 0.9767 - learning_rate: 7.4466e-07\n",
      "Epoch 51/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.5843 - loss: 0.9165 - val_accuracy: 0.5508 - val_loss: 0.9766 - learning_rate: 6.7379e-07\n",
      "Epoch 52/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.5877 - loss: 0.9123 - val_accuracy: 0.5508 - val_loss: 0.9765 - learning_rate: 6.0967e-07\n",
      "Epoch 53/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.5911 - loss: 0.9129 - val_accuracy: 0.5509 - val_loss: 0.9764 - learning_rate: 5.5166e-07\n",
      "Epoch 54/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.5972 - loss: 0.9079 - val_accuracy: 0.5509 - val_loss: 0.9763 - learning_rate: 4.9916e-07\n",
      "Epoch 55/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 151ms/step - accuracy: 0.5940 - loss: 0.9102 - val_accuracy: 0.5508 - val_loss: 0.9762 - learning_rate: 4.5166e-07\n",
      "Epoch 56/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 152ms/step - accuracy: 0.5918 - loss: 0.9111 - val_accuracy: 0.5512 - val_loss: 0.9761 - learning_rate: 4.0868e-07\n",
      "Epoch 57/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.5964 - loss: 0.9069 - val_accuracy: 0.5511 - val_loss: 0.9761 - learning_rate: 3.6979e-07\n",
      "Epoch 58/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.5907 - loss: 0.9121 - val_accuracy: 0.5514 - val_loss: 0.9760 - learning_rate: 3.3460e-07\n",
      "Epoch 59/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.5978 - loss: 0.9044 - val_accuracy: 0.5517 - val_loss: 0.9759 - learning_rate: 3.0276e-07\n",
      "Epoch 60/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5932 - loss: 0.9101 - val_accuracy: 0.5517 - val_loss: 0.9759 - learning_rate: 2.7394e-07\n",
      "Epoch 61/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 143ms/step - accuracy: 0.5951 - loss: 0.9081 - val_accuracy: 0.5517 - val_loss: 0.9758 - learning_rate: 2.4788e-07\n",
      "Epoch 62/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 144ms/step - accuracy: 0.5929 - loss: 0.9079 - val_accuracy: 0.5517 - val_loss: 0.9758 - learning_rate: 2.2429e-07\n",
      "Epoch 63/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 144ms/step - accuracy: 0.5932 - loss: 0.9100 - val_accuracy: 0.5517 - val_loss: 0.9758 - learning_rate: 2.0294e-07\n",
      "Epoch 64/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 144ms/step - accuracy: 0.5886 - loss: 0.9146 - val_accuracy: 0.5517 - val_loss: 0.9757 - learning_rate: 1.8363e-07\n",
      "Epoch 65/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 144ms/step - accuracy: 0.5875 - loss: 0.9131 - val_accuracy: 0.5517 - val_loss: 0.9757 - learning_rate: 1.6616e-07\n",
      "Epoch 66/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 144ms/step - accuracy: 0.5906 - loss: 0.9077 - val_accuracy: 0.5517 - val_loss: 0.9757 - learning_rate: 1.5034e-07\n",
      "Epoch 67/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 145ms/step - accuracy: 0.5901 - loss: 0.9099 - val_accuracy: 0.5517 - val_loss: 0.9756 - learning_rate: 1.3604e-07\n",
      "Epoch 68/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 144ms/step - accuracy: 0.5915 - loss: 0.9091 - val_accuracy: 0.5517 - val_loss: 0.9756 - learning_rate: 1.2309e-07\n",
      "Epoch 69/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 144ms/step - accuracy: 0.5924 - loss: 0.9113 - val_accuracy: 0.5517 - val_loss: 0.9756 - learning_rate: 1.1138e-07\n",
      "Epoch 70/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 145ms/step - accuracy: 0.5948 - loss: 0.9072 - val_accuracy: 0.5517 - val_loss: 0.9756 - learning_rate: 1.0078e-07\n",
      "Epoch 71/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 144ms/step - accuracy: 0.5898 - loss: 0.9104 - val_accuracy: 0.5517 - val_loss: 0.9756 - learning_rate: 9.1188e-08\n",
      "Epoch 72/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.5956 - loss: 0.9067 - val_accuracy: 0.5517 - val_loss: 0.9755 - learning_rate: 8.2510e-08\n",
      "Epoch 73/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 150ms/step - accuracy: 0.5933 - loss: 0.9073 - val_accuracy: 0.5517 - val_loss: 0.9755 - learning_rate: 7.4659e-08\n",
      "Epoch 74/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.5964 - loss: 0.9073 - val_accuracy: 0.5517 - val_loss: 0.9755 - learning_rate: 6.7554e-08\n",
      "Epoch 75/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 151ms/step - accuracy: 0.5882 - loss: 0.9147 - val_accuracy: 0.5517 - val_loss: 0.9755 - learning_rate: 6.1125e-08\n",
      "Epoch 76/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 145ms/step - accuracy: 0.5947 - loss: 0.9070 - val_accuracy: 0.5517 - val_loss: 0.9755 - learning_rate: 5.5308e-08\n",
      "Epoch 77/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.5919 - loss: 0.9119 - val_accuracy: 0.5517 - val_loss: 0.9755 - learning_rate: 5.0045e-08\n",
      "Epoch 78/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 151ms/step - accuracy: 0.5955 - loss: 0.9086 - val_accuracy: 0.5517 - val_loss: 0.9755 - learning_rate: 4.5283e-08\n",
      "Epoch 79/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 149ms/step - accuracy: 0.5924 - loss: 0.9072 - val_accuracy: 0.5517 - val_loss: 0.9755 - learning_rate: 4.0973e-08\n",
      "Epoch 80/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.5967 - loss: 0.9052 - val_accuracy: 0.5517 - val_loss: 0.9755 - learning_rate: 3.7074e-08\n",
      "Epoch 81/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 144ms/step - accuracy: 0.5969 - loss: 0.9092 - val_accuracy: 0.5517 - val_loss: 0.9755 - learning_rate: 3.3546e-08\n",
      "Epoch 82/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 147ms/step - accuracy: 0.5908 - loss: 0.9130 - val_accuracy: 0.5517 - val_loss: 0.9755 - learning_rate: 3.0354e-08\n",
      "Epoch 83/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.5917 - loss: 0.9102 - val_accuracy: 0.5517 - val_loss: 0.9754 - learning_rate: 2.7465e-08\n",
      "Epoch 84/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 148ms/step - accuracy: 0.5995 - loss: 0.9050 - val_accuracy: 0.5517 - val_loss: 0.9754 - learning_rate: 2.4852e-08\n",
      "Epoch 85/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 146ms/step - accuracy: 0.5866 - loss: 0.9111 - val_accuracy: 0.5517 - val_loss: 0.9754 - learning_rate: 2.2487e-08\n",
      "Epoch 86/100\n",
      "\u001b[1m 62/301\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 139ms/step - accuracy: 0.5766 - loss: 0.9170"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m x_train_lstm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(x_train_transformed\u001b[38;5;241m.\u001b[39mtoarray(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m x_valid_lstm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(x_valid_transformed\u001b[38;5;241m.\u001b[39mtoarray(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m lstm, lstm_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_lstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_valid_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 47\u001b[0m, in \u001b[0;36mtrain_lstm\u001b[1;34m(x_train, x_valid, y_train, y_valid)\u001b[0m\n\u001b[0;32m     41\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     43\u001b[0m lstm\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     44\u001b[0m                 optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(),\n\u001b[0;32m     45\u001b[0m                 metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 47\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mlstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m     55\u001b[0m lstm\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Egen\\Kuliah\\Discover NUS\\Natural Language Processing\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Egen\\Kuliah\\Discover NUS\\Natural Language Processing\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32md:\\Egen\\Kuliah\\Discover NUS\\Natural Language Processing\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32md:\\Egen\\Kuliah\\Discover NUS\\Natural Language Processing\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Egen\\Kuliah\\Discover NUS\\Natural Language Processing\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Egen\\Kuliah\\Discover NUS\\Natural Language Processing\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Egen\\Kuliah\\Discover NUS\\Natural Language Processing\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Egen\\Kuliah\\Discover NUS\\Natural Language Processing\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Egen\\Kuliah\\Discover NUS\\Natural Language Processing\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32md:\\Egen\\Kuliah\\Discover NUS\\Natural Language Processing\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32md:\\Egen\\Kuliah\\Discover NUS\\Natural Language Processing\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32md:\\Egen\\Kuliah\\Discover NUS\\Natural Language Processing\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train_lstm = np.expand_dims(x_train_transformed.toarray(), axis=1)\n",
    "x_valid_lstm = np.expand_dims(x_valid_transformed.toarray(), axis=1)\n",
    "lstm, lstm_history = train_lstm(x_train_lstm, x_valid_lstm, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 20000\n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "x_valid_seq = tokenizer.texts_to_sequences(x_valid)\n",
    "\n",
    "x_train_padded = pad_sequences(x_train_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "x_valid_padded = pad_sequences(x_valid_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "y_train_categorical = tf.keras.utils.to_categorical(y_train, num_classes=3)\n",
    "y_valid_categorical = tf.keras.utils.to_categorical(y_valid, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_semantic_model(x_train, x_valid, y_train, y_valid):\n",
    "    input_layer = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "    \n",
    "    # Embedding layer (Trainable)\n",
    "    embedding_layer = Embedding(input_dim=MAX_NUM_WORDS, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)(input_layer)\n",
    "\n",
    "    # Instead of LSTM, use GlobalAveragePooling1D to reduce dimensions\n",
    "    x = GlobalAveragePooling1D()(embedding_layer)\n",
    "\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    output_layer = Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-4 * math.exp(-0.1 * x))\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=tf.optimizers.Adam(),\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(x_train, y_train,                   \n",
    "                        epochs=100,\n",
    "                        validation_data=(x_valid, y_valid),\n",
    "                        batch_size=64,\n",
    "                        verbose=1,\n",
    "                        callbacks=[lr_scheduler, early_stopping])\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Egen\\Kuliah\\Discover NUS\\Natural Language Processing\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.3896 - loss: 1.0917 - val_accuracy: 0.4045 - val_loss: 1.0864 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4060 - loss: 1.0871 - val_accuracy: 0.4045 - val_loss: 1.0864 - learning_rate: 9.0484e-05\n",
      "Epoch 3/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4125 - loss: 1.0844 - val_accuracy: 0.4045 - val_loss: 1.0861 - learning_rate: 8.1873e-05\n",
      "Epoch 4/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4063 - loss: 1.0864 - val_accuracy: 0.4045 - val_loss: 1.0861 - learning_rate: 7.4082e-05\n",
      "Epoch 5/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4072 - loss: 1.0853 - val_accuracy: 0.4045 - val_loss: 1.0859 - learning_rate: 6.7032e-05\n",
      "Epoch 6/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4087 - loss: 1.0854 - val_accuracy: 0.4045 - val_loss: 1.0855 - learning_rate: 6.0653e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4122 - loss: 1.0834 - val_accuracy: 0.4045 - val_loss: 1.0851 - learning_rate: 5.4881e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4059 - loss: 1.0844 - val_accuracy: 0.4045 - val_loss: 1.0845 - learning_rate: 4.9659e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4101 - loss: 1.0836 - val_accuracy: 0.4045 - val_loss: 1.0839 - learning_rate: 4.4933e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4017 - loss: 1.0850 - val_accuracy: 0.4045 - val_loss: 1.0830 - learning_rate: 4.0657e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4090 - loss: 1.0816 - val_accuracy: 0.4045 - val_loss: 1.0824 - learning_rate: 3.6788e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4056 - loss: 1.0822 - val_accuracy: 0.4045 - val_loss: 1.0811 - learning_rate: 3.3287e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4081 - loss: 1.0803 - val_accuracy: 0.4045 - val_loss: 1.0793 - learning_rate: 3.0119e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4060 - loss: 1.0787 - val_accuracy: 0.4045 - val_loss: 1.0778 - learning_rate: 2.7253e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4068 - loss: 1.0772 - val_accuracy: 0.4045 - val_loss: 1.0760 - learning_rate: 2.4660e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4057 - loss: 1.0755 - val_accuracy: 0.4045 - val_loss: 1.0741 - learning_rate: 2.2313e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4063 - loss: 1.0734 - val_accuracy: 0.4045 - val_loss: 1.0719 - learning_rate: 2.0190e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.3993 - loss: 1.0726 - val_accuracy: 0.4045 - val_loss: 1.0696 - learning_rate: 1.8268e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4112 - loss: 1.0672 - val_accuracy: 0.4054 - val_loss: 1.0673 - learning_rate: 1.6530e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4047 - loss: 1.0680 - val_accuracy: 0.4051 - val_loss: 1.0646 - learning_rate: 1.4957e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4081 - loss: 1.0642 - val_accuracy: 0.4088 - val_loss: 1.0623 - learning_rate: 1.3534e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4061 - loss: 1.0632 - val_accuracy: 0.4112 - val_loss: 1.0601 - learning_rate: 1.2246e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4115 - loss: 1.0591 - val_accuracy: 0.4184 - val_loss: 1.0582 - learning_rate: 1.1080e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4162 - loss: 1.0564 - val_accuracy: 0.4180 - val_loss: 1.0558 - learning_rate: 1.0026e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4242 - loss: 1.0528 - val_accuracy: 0.4201 - val_loss: 1.0541 - learning_rate: 9.0718e-06\n",
      "Epoch 26/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4198 - loss: 1.0523 - val_accuracy: 0.4195 - val_loss: 1.0523 - learning_rate: 8.2085e-06\n",
      "Epoch 27/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4248 - loss: 1.0491 - val_accuracy: 0.4255 - val_loss: 1.0506 - learning_rate: 7.4274e-06\n",
      "Epoch 28/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4278 - loss: 1.0485 - val_accuracy: 0.4273 - val_loss: 1.0491 - learning_rate: 6.7206e-06\n",
      "Epoch 29/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4273 - loss: 1.0479 - val_accuracy: 0.4262 - val_loss: 1.0477 - learning_rate: 6.0810e-06\n",
      "Epoch 30/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4336 - loss: 1.0437 - val_accuracy: 0.4244 - val_loss: 1.0466 - learning_rate: 5.5023e-06\n",
      "Epoch 31/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4290 - loss: 1.0450 - val_accuracy: 0.4272 - val_loss: 1.0452 - learning_rate: 4.9787e-06\n",
      "Epoch 32/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4304 - loss: 1.0430 - val_accuracy: 0.4334 - val_loss: 1.0440 - learning_rate: 4.5049e-06\n",
      "Epoch 33/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4429 - loss: 1.0408 - val_accuracy: 0.4326 - val_loss: 1.0430 - learning_rate: 4.0762e-06\n",
      "Epoch 34/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4444 - loss: 1.0392 - val_accuracy: 0.4340 - val_loss: 1.0421 - learning_rate: 3.6883e-06\n",
      "Epoch 35/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4479 - loss: 1.0375 - val_accuracy: 0.4309 - val_loss: 1.0415 - learning_rate: 3.3373e-06\n",
      "Epoch 36/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4442 - loss: 1.0384 - val_accuracy: 0.4329 - val_loss: 1.0407 - learning_rate: 3.0197e-06\n",
      "Epoch 37/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4404 - loss: 1.0393 - val_accuracy: 0.4339 - val_loss: 1.0400 - learning_rate: 2.7324e-06\n",
      "Epoch 38/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4418 - loss: 1.0371 - val_accuracy: 0.4379 - val_loss: 1.0392 - learning_rate: 2.4724e-06\n",
      "Epoch 39/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4461 - loss: 1.0364 - val_accuracy: 0.4427 - val_loss: 1.0387 - learning_rate: 2.2371e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4447 - loss: 1.0379 - val_accuracy: 0.4431 - val_loss: 1.0381 - learning_rate: 2.0242e-06\n",
      "Epoch 41/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4512 - loss: 1.0355 - val_accuracy: 0.4442 - val_loss: 1.0377 - learning_rate: 1.8316e-06\n",
      "Epoch 42/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4512 - loss: 1.0349 - val_accuracy: 0.4435 - val_loss: 1.0372 - learning_rate: 1.6573e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4567 - loss: 1.0344 - val_accuracy: 0.4423 - val_loss: 1.0368 - learning_rate: 1.4996e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4465 - loss: 1.0354 - val_accuracy: 0.4423 - val_loss: 1.0365 - learning_rate: 1.3569e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4496 - loss: 1.0332 - val_accuracy: 0.4434 - val_loss: 1.0361 - learning_rate: 1.2277e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.4524 - loss: 1.0324 - val_accuracy: 0.4447 - val_loss: 1.0358 - learning_rate: 1.1109e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.4531 - loss: 1.0334 - val_accuracy: 0.4442 - val_loss: 1.0356 - learning_rate: 1.0052e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4504 - loss: 1.0338 - val_accuracy: 0.4451 - val_loss: 1.0353 - learning_rate: 9.0953e-07\n",
      "Epoch 49/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4625 - loss: 1.0319 - val_accuracy: 0.4452 - val_loss: 1.0351 - learning_rate: 8.2297e-07\n",
      "Epoch 50/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4486 - loss: 1.0334 - val_accuracy: 0.4453 - val_loss: 1.0349 - learning_rate: 7.4466e-07\n",
      "Epoch 51/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4468 - loss: 1.0329 - val_accuracy: 0.4465 - val_loss: 1.0347 - learning_rate: 6.7379e-07\n",
      "Epoch 52/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4565 - loss: 1.0320 - val_accuracy: 0.4457 - val_loss: 1.0346 - learning_rate: 6.0967e-07\n",
      "Epoch 53/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4548 - loss: 1.0305 - val_accuracy: 0.4457 - val_loss: 1.0344 - learning_rate: 5.5166e-07\n",
      "Epoch 54/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4543 - loss: 1.0324 - val_accuracy: 0.4457 - val_loss: 1.0343 - learning_rate: 4.9916e-07\n",
      "Epoch 55/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4547 - loss: 1.0310 - val_accuracy: 0.4457 - val_loss: 1.0342 - learning_rate: 4.5166e-07\n",
      "Epoch 56/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4566 - loss: 1.0313 - val_accuracy: 0.4469 - val_loss: 1.0341 - learning_rate: 4.0868e-07\n",
      "Epoch 57/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4522 - loss: 1.0328 - val_accuracy: 0.4455 - val_loss: 1.0340 - learning_rate: 3.6979e-07\n",
      "Epoch 58/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4504 - loss: 1.0333 - val_accuracy: 0.4467 - val_loss: 1.0339 - learning_rate: 3.3460e-07\n",
      "Epoch 59/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4496 - loss: 1.0318 - val_accuracy: 0.4461 - val_loss: 1.0338 - learning_rate: 3.0276e-07\n",
      "Epoch 60/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4561 - loss: 1.0312 - val_accuracy: 0.4465 - val_loss: 1.0337 - learning_rate: 2.7394e-07\n",
      "Epoch 61/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4616 - loss: 1.0296 - val_accuracy: 0.4464 - val_loss: 1.0337 - learning_rate: 2.4788e-07\n",
      "Epoch 62/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4614 - loss: 1.0294 - val_accuracy: 0.4470 - val_loss: 1.0336 - learning_rate: 2.2429e-07\n",
      "Epoch 63/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4556 - loss: 1.0291 - val_accuracy: 0.4467 - val_loss: 1.0335 - learning_rate: 2.0294e-07\n",
      "Epoch 64/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4595 - loss: 1.0295 - val_accuracy: 0.4472 - val_loss: 1.0335 - learning_rate: 1.8363e-07\n",
      "Epoch 65/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4628 - loss: 1.0301 - val_accuracy: 0.4472 - val_loss: 1.0334 - learning_rate: 1.6616e-07\n",
      "Epoch 66/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4567 - loss: 1.0309 - val_accuracy: 0.4474 - val_loss: 1.0334 - learning_rate: 1.5034e-07\n",
      "Epoch 67/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4555 - loss: 1.0307 - val_accuracy: 0.4472 - val_loss: 1.0334 - learning_rate: 1.3604e-07\n",
      "Epoch 68/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4604 - loss: 1.0284 - val_accuracy: 0.4472 - val_loss: 1.0333 - learning_rate: 1.2309e-07\n",
      "Epoch 69/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4584 - loss: 1.0311 - val_accuracy: 0.4471 - val_loss: 1.0333 - learning_rate: 1.1138e-07\n",
      "Epoch 70/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4568 - loss: 1.0314 - val_accuracy: 0.4471 - val_loss: 1.0333 - learning_rate: 1.0078e-07\n",
      "Epoch 71/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4569 - loss: 1.0302 - val_accuracy: 0.4474 - val_loss: 1.0333 - learning_rate: 9.1188e-08\n",
      "Epoch 72/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4565 - loss: 1.0297 - val_accuracy: 0.4471 - val_loss: 1.0332 - learning_rate: 8.2510e-08\n",
      "Epoch 73/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4511 - loss: 1.0315 - val_accuracy: 0.4474 - val_loss: 1.0332 - learning_rate: 7.4659e-08\n",
      "Epoch 74/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4547 - loss: 1.0311 - val_accuracy: 0.4472 - val_loss: 1.0332 - learning_rate: 6.7554e-08\n",
      "Epoch 75/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4539 - loss: 1.0310 - val_accuracy: 0.4474 - val_loss: 1.0332 - learning_rate: 6.1125e-08\n",
      "Epoch 76/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4699 - loss: 1.0282 - val_accuracy: 0.4474 - val_loss: 1.0332 - learning_rate: 5.5308e-08\n",
      "Epoch 77/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4583 - loss: 1.0305 - val_accuracy: 0.4474 - val_loss: 1.0331 - learning_rate: 5.0045e-08\n",
      "Epoch 78/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4611 - loss: 1.0298 - val_accuracy: 0.4475 - val_loss: 1.0331 - learning_rate: 4.5283e-08\n",
      "Epoch 79/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4598 - loss: 1.0300 - val_accuracy: 0.4475 - val_loss: 1.0331 - learning_rate: 4.0973e-08\n",
      "Epoch 80/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4622 - loss: 1.0287 - val_accuracy: 0.4475 - val_loss: 1.0331 - learning_rate: 3.7074e-08\n",
      "Epoch 81/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4550 - loss: 1.0325 - val_accuracy: 0.4475 - val_loss: 1.0331 - learning_rate: 3.3546e-08\n",
      "Epoch 82/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4603 - loss: 1.0291 - val_accuracy: 0.4475 - val_loss: 1.0331 - learning_rate: 3.0354e-08\n",
      "Epoch 83/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4637 - loss: 1.0289 - val_accuracy: 0.4475 - val_loss: 1.0331 - learning_rate: 2.7465e-08\n",
      "Epoch 84/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4559 - loss: 1.0305 - val_accuracy: 0.4475 - val_loss: 1.0331 - learning_rate: 2.4852e-08\n",
      "Epoch 85/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4550 - loss: 1.0308 - val_accuracy: 0.4475 - val_loss: 1.0331 - learning_rate: 2.2487e-08\n",
      "Epoch 86/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4510 - loss: 1.0318 - val_accuracy: 0.4475 - val_loss: 1.0331 - learning_rate: 2.0347e-08\n",
      "Epoch 87/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4548 - loss: 1.0312 - val_accuracy: 0.4475 - val_loss: 1.0331 - learning_rate: 1.8411e-08\n",
      "Epoch 88/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4576 - loss: 1.0301 - val_accuracy: 0.4475 - val_loss: 1.0331 - learning_rate: 1.6659e-08\n",
      "Epoch 89/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4587 - loss: 1.0303 - val_accuracy: 0.4475 - val_loss: 1.0331 - learning_rate: 1.5073e-08\n",
      "Epoch 90/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4539 - loss: 1.0313 - val_accuracy: 0.4475 - val_loss: 1.0331 - learning_rate: 1.3639e-08\n",
      "Epoch 91/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4623 - loss: 1.0320 - val_accuracy: 0.4475 - val_loss: 1.0331 - learning_rate: 1.2341e-08\n",
      "Epoch 92/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4540 - loss: 1.0308 - val_accuracy: 0.4475 - val_loss: 1.0330 - learning_rate: 1.1167e-08\n",
      "Epoch 93/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4618 - loss: 1.0301 - val_accuracy: 0.4475 - val_loss: 1.0330 - learning_rate: 1.0104e-08\n",
      "Epoch 94/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4568 - loss: 1.0304 - val_accuracy: 0.4475 - val_loss: 1.0330 - learning_rate: 9.1424e-09\n",
      "Epoch 95/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4584 - loss: 1.0311 - val_accuracy: 0.4475 - val_loss: 1.0330 - learning_rate: 8.2724e-09\n",
      "Epoch 96/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4516 - loss: 1.0331 - val_accuracy: 0.4475 - val_loss: 1.0330 - learning_rate: 7.4852e-09\n",
      "Epoch 97/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4607 - loss: 1.0291 - val_accuracy: 0.4475 - val_loss: 1.0330 - learning_rate: 6.7729e-09\n",
      "Epoch 98/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4647 - loss: 1.0288 - val_accuracy: 0.4475 - val_loss: 1.0330 - learning_rate: 6.1283e-09\n",
      "Epoch 99/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4466 - loss: 1.0323 - val_accuracy: 0.4475 - val_loss: 1.0330 - learning_rate: 5.5452e-09\n",
      "Epoch 100/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4637 - loss: 1.0282 - val_accuracy: 0.4475 - val_loss: 1.0330 - learning_rate: 5.0175e-09\n"
     ]
    }
   ],
   "source": [
    "semantic_model, history_s = train_semantic_model(x_train_padded, x_valid_padded, y_train_categorical, y_valid_categorical)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
